{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# MLflow ResponseAgent - Basics\n",
        "\n",
        "This notebook introduces the **ResponseAgent** class in MLflow and explains why it's needed for building production-ready AI agents.\n",
        "\n",
        "## Table of Contents\n",
        "1. What is ResponseAgent?\n",
        "2. Why Do We Need ResponseAgent?\n",
        "3. Key Features\n",
        "4. Basic ResponseAgent Implementation\n",
        "5. Comparison with ChatAgent"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Setup"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "MLflow version: 3.8.1\n"
          ]
        }
      ],
      "source": [
        "import os\n",
        "from dotenv import load_dotenv\n",
        "import mlflow\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import (\n",
        "    ResponsesAgentRequest,\n",
        "    ResponsesAgentResponse,\n",
        "    ResponsesAgentStreamEvent,\n",
        ")\n",
        "from typing import Generator\n",
        "\n",
        "# Load environment variables\n",
        "load_dotenv()\n",
        "\n",
        "# Set MLflow tracking\n",
        "mlflow.set_experiment(\"ResponseAgent_Basics\")\n",
        "\n",
        "print(f\"MLflow version: {mlflow.__version__}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 1. What is ResponseAgent?\n",
        "\n",
        "**ResponseAgent** is a specialized subclass of MLflow's `PythonModel` that provides a **framework-agnostic** interface for serving generative AI models with advanced capabilities.\n",
        "\n",
        "### Key Characteristics:\n",
        "- **Subclass of PythonModel**: Inherits all MLflow model capabilities\n",
        "- **Framework-agnostic**: Works with any agent framework (LangGraph, LangChain, custom implementations)\n",
        "- **OpenAI API Compatible**: Follows OpenAI's Responses API standard\n",
        "- **Structured I/O**: Uses well-defined request/response schemas\n",
        "- **Production-ready**: Built for deployment and serving"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 2. Why Do We Need ResponseAgent?\n",
        "\n",
        "### Problems with Traditional Approaches:\n",
        "\n",
        "1. **Framework Lock-in**: Agents built with specific frameworks are hard to migrate\n",
        "2. **No Standardized I/O**: Different agents use different message formats\n",
        "3. **Tool Calling Complexity**: Handling function calls requires custom logic\n",
        "4. **Multi-agent Support**: Traditional models don't support multi-agent scenarios\n",
        "5. **Deployment Challenges**: Difficult to serve and scale custom agents\n",
        "6. **Observability Gaps**: Hard to track intermediate steps in agent execution\n",
        "\n",
        "### How ResponseAgent Solves These:\n",
        "\n",
        "✅ **Framework Independence**: Wrap any agent implementation\n",
        "\n",
        "✅ **Standard Interface**: OpenAI Responses API compatibility\n",
        "\n",
        "✅ **Built-in Tool Support**: Native function calling capabilities\n",
        "\n",
        "✅ **Multi-agent Ready**: Support for complex agent interactions\n",
        "\n",
        "✅ **Easy Deployment**: Log once, deploy anywhere with MLflow\n",
        "\n",
        "✅ **Full Tracing**: Integrated with MLflow tracing for observability"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 3. Key Features\n",
        "\n",
        "### Feature Comparison Table\n",
        "\n",
        "| Feature | ChatModel | ChatAgent | ResponseAgent |\n",
        "|---------|-----------|-----------|---------------|\n",
        "| Basic Chat | ✅ | ✅ | ✅ |\n",
        "| Tool Calling | ❌ | ✅ | ✅ |\n",
        "| Multi-turn Dialog | ✅ | ✅ | ✅ |\n",
        "| Streaming | ✅ | ✅ | ✅ |\n",
        "| Multi-agent | ❌ | ❌ | ✅ |\n",
        "| OpenAI Compatible | ❌ | ⚠️ Partial | ✅ Full |\n",
        "| Intermediate Outputs | ❌ | ⚠️ Limited | ✅ Full |\n",
        "| Annotations | ❌ | ❌ | ✅ |\n",
        "| Custom Outputs | ❌ | ❌ | ✅ |\n",
        "\n",
        "### ResponseAgent Advantages:\n",
        "\n",
        "1. **Multiple Output Messages**: Return intermediate tool calls and results\n",
        "2. **Multi-agent Orchestration**: Coordinate between multiple AI agents\n",
        "3. **Full OpenAI Compatibility**: Works with OpenAI SDKs and UIs\n",
        "4. **Flexible Output**: Custom outputs via `custom_outputs` field\n",
        "5. **Enhanced Tracing**: Better observability for debugging"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 4. Basic ResponseAgent Implementation\n",
        "\n",
        "Let's create a simple ResponseAgent that demonstrates core concepts."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "2026/01/29 10:12:22 WARNING mlflow.pyfunc: You have manually traced predict with @mlflow.trace, but this is unnecessary with ResponsesAgent subclasses. You can remove the @mlflow.trace decorator and it will be automatically traced.\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Testing SimpleResponsesAgent...\n",
            "\n"
          ]
        },
        {
          "data": {
            "text/plain": [
              "ResponsesAgentResponse(tool_choice=None, truncation=None, id=None, created_at=None, error=None, incomplete_details=None, instructions=None, metadata=None, model=None, object='response', output=[OutputItem(type='message', id='msg_1', content=[{'text': \"Hello! You said: 'What is MLflow?'. How can I help you today?\", 'type': 'output_text'}], role='assistant')], parallel_tool_calls=None, temperature=None, tools=None, top_p=None, max_output_tokens=None, previous_response_id=None, reasoning=None, status=None, text=None, usage=None, user=None, custom_outputs={'agent_type': 'simple_echo', 'processed_at': '2026-01-29'})"
            ]
          },
          "execution_count": null,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "from mlflow.entities.span import SpanType\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import (\n",
        "    ResponsesAgentRequest,\n",
        "    ResponsesAgentResponse,\n",
        ")\n",
        "\n",
        "\n",
        "class SimpleResponsesAgent(ResponsesAgent):\n",
        "    \"\"\"\n",
        "    A basic ResponseAgent that echoes user messages with a greeting.\n",
        "    \n",
        "    This demonstrates:\n",
        "    - Basic ResponseAgent structure\n",
        "    - Request/Response handling\n",
        "    - Text output creation\n",
        "    - Custom outputs\n",
        "    \"\"\"\n",
        "    \n",
        "    @mlflow.trace(span_type=SpanType.AGENT)\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        \"\"\"\n",
        "        Main prediction method.\n",
        "        \n",
        "        Args:\n",
        "            request: ResponsesAgentRequest with user input\n",
        "            \n",
        "        Returns:\n",
        "            ResponsesAgentResponse with agent output\n",
        "        \"\"\"\n",
        "        # Extract user message from request\n",
        "        user_message = request.input[-1].content\n",
        "        \n",
        "        # Create response text\n",
        "        response_text = f\"Hello! You said: '{user_message}'. How can I help you today?\"\n",
        "        \n",
        "        # Create structured response\n",
        "        return ResponsesAgentResponse(\n",
        "            output=[\n",
        "                self.create_text_output_item(\n",
        "                    text=response_text,\n",
        "                    id=\"msg_1\",\n",
        "                )\n",
        "            ],\n",
        "            # Add custom metadata\n",
        "            custom_outputs={\n",
        "                \"agent_type\": \"simple_echo\",\n",
        "                \"processed_at\": \"2026-01-29\",\n",
        "            },\n",
        "        )\n",
        "\n",
        "\n",
        "# Test the agent\n",
        "print(\"Testing SimpleResponsesAgent...\\n\")\n",
        "agent = SimpleResponsesAgent()\n",
        "\n",
        "# Create a test request\n",
        "test_request = {\n",
        "    \"input\": [{\"role\": \"user\", \"content\": \"What is MLflow?\"}],\n",
        "    \"context\": {\"user_id\": \"test_user\", \"session_id\": \"session_123\"},\n",
        "}\n",
        "\n",
        "# Get response\n",
        "response = agent.predict(test_request)\n",
        "response\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Agent Response: Hello! You said: 'What is MLflow?'. How can I help you today?\n",
            "Custom Outputs: {'agent_type': 'simple_echo', 'processed_at': '2026-01-29'}\n",
            "\n",
            "Output Item Type: message\n",
            "Output Item ID: msg_1\n",
            "Output Item Role: assistant\n"
          ]
        }
      ],
      "source": [
        "# Access OutputItem properties correctly (it's a Pydantic model, not a dict)\n",
        "output_item = response.output[0]\n",
        "print(f\"Agent Response: {output_item.content[0]['text']}\")\n",
        "print(f\"Custom Outputs: {response.custom_outputs}\")\n",
        "print(f\"\\nOutput Item Type: {output_item.type}\")\n",
        "print(f\"Output Item ID: {output_item.id}\")\n",
        "print(f\"Output Item Role: {output_item.role}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 5. Understanding Request and Response Schemas\n",
        "\n",
        "### ResponsesAgentRequest Schema\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"input\": [  # List of messages\n",
        "        {\n",
        "            \"role\": \"user\" | \"assistant\" | \"system\",\n",
        "            \"content\": \"message text\"\n",
        "        }\n",
        "    ],\n",
        "    \"context\": {  # Optional context data\n",
        "        \"user_id\": \"...\",\n",
        "        \"session_id\": \"...\",\n",
        "        # Any custom fields\n",
        "    },\n",
        "    \"tools\": [...]  # Optional tool definitions\n",
        "}\n",
        "```\n",
        "\n",
        "### ResponsesAgentResponse Schema\n",
        "\n",
        "```python\n",
        "{\n",
        "    \"output\": [  # List of output items\n",
        "        {\n",
        "            \"type\": \"message\",\n",
        "            \"id\": \"msg_1\",\n",
        "            \"role\": \"assistant\",\n",
        "            \"content\": [\n",
        "                {\n",
        "                    \"type\": \"output_text\",\n",
        "                    \"text\": \"response text\"\n",
        "                }\n",
        "            ]\n",
        "        }\n",
        "    ],\n",
        "    \"custom_outputs\": {  # Optional custom data\n",
        "        \"key\": \"value\"\n",
        "    }\n",
        "}\n",
        "```"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 6. Helper Methods in ResponseAgent\n",
        "\n",
        "ResponseAgent provides convenient helper methods for creating outputs:"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Example of all helper methods\n",
        "class DemoAgent(ResponsesAgent):\n",
        "    @mlflow.trace(span_type=SpanType.AGENT)\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        outputs = []\n",
        "        \n",
        "        # 1. Text output\n",
        "        outputs.append(\n",
        "            self.create_text_output_item(\n",
        "                text=\"This is a text response\",\n",
        "                id=\"text_1\"\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        # 2. Function call (tool invocation)\n",
        "        outputs.append(\n",
        "            self.create_function_call_item(\n",
        "                id=\"fc_1\",\n",
        "                call_id=\"call_123\",\n",
        "                name=\"calculator\",\n",
        "                arguments='{\"operation\": \"add\", \"x\": 5, \"y\": 3}'\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        # 3. Function call output (tool result)\n",
        "        outputs.append(\n",
        "            self.create_function_call_output_item(\n",
        "                call_id=\"call_123\",\n",
        "                output=\"8\"\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        # 4. Reasoning (chain-of-thought)\n",
        "        outputs.append(\n",
        "            self.create_reasoning_item(\n",
        "                text=\"Let me think step by step...\",\n",
        "                id=\"reason_1\"\n",
        "            )\n",
        "        )\n",
        "        \n",
        "        return ResponsesAgentResponse(output=outputs)\n",
        "\n",
        "# Note: This is just a demonstration of available methods\n",
        "print(\"✅ Helper methods demonstrated above\")\n",
        "print(\"\\nAvailable helper methods:\")\n",
        "print(\"1. create_text_output_item()\")\n",
        "print(\"2. create_function_call_item()\")\n",
        "print(\"3. create_function_call_output_item()\")\n",
        "print(\"4. create_reasoning_item()\")\n",
        "print(\"5. create_text_delta() - for streaming\")\n",
        "print(\"6. create_annotation_added() - for streaming\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 7. Logging a ResponseAgent\n",
        "\n",
        "MLflow uses the \"Models from Code\" approach for logging ResponseAgent."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Save our agent to a Python file\n",
        "agent_code = '''\n",
        "import mlflow\n",
        "from mlflow.entities.span import SpanType\n",
        "from mlflow.pyfunc import ResponsesAgent\n",
        "from mlflow.types.responses import (\n",
        "    ResponsesAgentRequest,\n",
        "    ResponsesAgentResponse,\n",
        ")\n",
        "\n",
        "\n",
        "class SimpleResponsesAgent(ResponsesAgent):\n",
        "    @mlflow.trace(span_type=SpanType.AGENT)\n",
        "    def predict(self, request: ResponsesAgentRequest) -> ResponsesAgentResponse:\n",
        "        user_message = request.input[-1].content\n",
        "        response_text = f\"Echo: {user_message}\"\n",
        "        \n",
        "        return ResponsesAgentResponse(\n",
        "            output=[\n",
        "                self.create_text_output_item(\n",
        "                    text=response_text,\n",
        "                    id=\"msg_1\",\n",
        "                )\n",
        "            ]\n",
        "        )\n",
        "\n",
        "\n",
        "# Set model for MLflow\n",
        "mlflow.models.set_model(SimpleResponsesAgent())\n",
        "'''\n",
        "\n",
        "# Write to file\n",
        "with open(\"simple_agent.py\", \"w\") as f:\n",
        "    f.write(agent_code)\n",
        "\n",
        "# Log the model\n",
        "with mlflow.start_run(run_name=\"simple_responses_agent\"):\n",
        "    model_info = mlflow.pyfunc.log_model(\n",
        "        python_model=\"simple_agent.py\",\n",
        "        artifact_path=\"agent\",\n",
        "        # Signature and metadata are auto-inferred for ResponseAgent\n",
        "    )\n",
        "    \n",
        "    print(f\"✅ Model logged successfully!\")\n",
        "    print(f\"Model URI: {model_info.model_uri}\")\n",
        "    print(f\"\\nAuto-generated metadata:\")\n",
        "    print(f\"  Task: {model_info.metadata.get('task', 'N/A')}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## 8. Loading and Testing the Logged Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load the model\n",
        "loaded_model = mlflow.pyfunc.load_model(model_info.model_uri)\n",
        "\n",
        "# Test it\n",
        "test_input = {\n",
        "    \"input\": [{\"role\": \"user\", \"content\": \"Hello, ResponseAgent!\"}],\n",
        "    \"context\": {\"user_id\": \"user_123\"},\n",
        "}\n",
        "\n",
        "response = loaded_model.predict(test_input)\n",
        "print(f\"Loaded model response: {response}\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "## Summary\n",
        "\n",
        "### What We Learned:\n",
        "\n",
        "1. ✅ **What is ResponseAgent**: Framework-agnostic agent interface\n",
        "2. ✅ **Why we need it**: Standardization, deployment, multi-agent support\n",
        "3. ✅ **Key features**: OpenAI compatibility, tool calling, streaming\n",
        "4. ✅ **Basic implementation**: Creating and using ResponseAgent\n",
        "5. ✅ **Logging and loading**: Models from code approach\n",
        "\n",
        "### Next Steps:\n",
        "- Proceed to notebook 03 for LangGraph integration\n",
        "- Learn about tool calling with ResponseAgent\n",
        "- Explore streaming responses\n",
        "- Deploy agents for production use"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 4
}
