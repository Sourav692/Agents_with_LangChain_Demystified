{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# 2.2 Prompt Templates in LangChain\n",
        "\n",
        "## üéØ Learning Objectives\n",
        "\n",
        "In this notebook, you'll learn how to create **dynamic, reusable prompts** using LangChain's template system:\n",
        "\n",
        "1. **PromptTemplate Basics** - Create parameterized prompts with variables\n",
        "2. **Few-Shot Prompting** - Improve LLM outputs with examples\n",
        "3. **Chain-of-Thought Prompting** - Guide reasoning step-by-step\n",
        "4. **Prompt Composition** - Build complex prompts from reusable parts\n",
        "5. **Serialization** - Save and load prompts from files\n",
        "\n",
        "## üí° Why Use Prompt Templates?\n",
        "\n",
        "Instead of hardcoding prompts like:\n",
        "```python\n",
        "SystemMessage(content=\"You are a helpful assistant that translates English to Spanish.\")\n",
        "```\n",
        "\n",
        "You can make them dynamic:\n",
        "```python\n",
        "template = \"You are a helpful assistant that translates {input_language} to {output_language}\"\n",
        "```\n",
        "\n",
        "---"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ENVIRONMENT SETUP: Load API Keys & Import Dependencies\n",
        "# ============================================================================\n",
        "# We use python-dotenv to securely load API keys from a .env file\n",
        "# This is a best practice - never hardcode API keys in your notebooks!\n",
        "# ============================================================================\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Add parent directory to path for importing helpers\n",
        "sys.path.append(os.path.abspath(\"../..\"))\n",
        "\n",
        "# Import our LLM factory functions\n",
        "# - get_groq_llm(): Creates a Groq-hosted LLM (fast inference with open-source models)\n",
        "# - get_openai_llm(): Creates an OpenAI GPT model\n",
        "# - get_databricks_llm(): Creates a Databricks-hosted LLM\n",
        "from helpers.utils import get_groq_llm, get_openai_llm, get_databricks_llm\n",
        "\n",
        "print(\"‚úÖ Environment variables loaded successfully!\")\n",
        "print(f\"üìç Running on: {platform.system()}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize the LLM based on platform or preference\n",
        "# The choice of LLM affects tool calling capabilities and speed\n",
        "# -----------------------------------------------------------------------------\n",
        "if sys.platform == \"win32\":\n",
        "    # Windows: Use Groq for fast inference\n",
        "    llm = get_groq_llm()\n",
        "elif sys.platform == \"darwin\":\n",
        "    # macOS: Use Databricks-hosted Gemini\n",
        "    llm = get_databricks_llm(\"databricks-gpt-5-1\")  \n",
        "else:\n",
        "    # Linux: Default to Groq\n",
        "    llm = get_groq_llm()\n",
        "\n",
        "# Print which LLM we're using\n",
        "if hasattr(llm, 'model_name'):\n",
        "    print(f\"ü§ñ LLM initialized: {llm.model_name}\")\n",
        "elif hasattr(llm, 'model'):\n",
        "    print(f\"ü§ñ LLM initialized: {llm.model}\")\n",
        "else:\n",
        "    print(\"ü§ñ LLM initialized successfully\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BASIC PROMPT TEMPLATE\n",
        "# ============================================================================\n",
        "# A PromptTemplate uses Python's str.format() syntax with {variable_name}\n",
        "# Variables are replaced with actual values when you call .format()\n",
        "# ============================================================================\n",
        "\n",
        "TEMPLATE = \"\"\"\n",
        "You are a helpful assistant that translates the {input_language} to {output_language}\n",
        "\"\"\"\n",
        "\n",
        "print(\"Template with placeholders:\")\n",
        "print(TEMPLATE)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CREATING A PROMPT TEMPLATE\n",
        "# ============================================================================\n",
        "# Method 1: .from_template() - Auto-detects variables from the template string\n",
        "# This is the quickest way when your template is straightforward\n",
        "# ============================================================================\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate\n",
        "\n",
        "# Create template - variables are automatically extracted from {placeholders}\n",
        "prompt_template = PromptTemplate.from_template(template=TEMPLATE)\n",
        "\n",
        "# Format the template with actual values\n",
        "formatted_prompt = prompt_template.format(input_language=\"english\", output_language=\"german\")\n",
        "\n",
        "print(\"üìù Formatted Prompt:\")\n",
        "print(formatted_prompt)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Method 2: Explicit Variable Declaration\n",
        "\n",
        "Passing `input_variables` to the constructor provides **validation** - LangChain will raise an error if you forget a variable or have a typo."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# METHOD 2: Explicit Variable Declaration (Recommended for Production)\n",
        "# ============================================================================\n",
        "# By specifying input_variables, you get:\n",
        "# - Validation that all variables exist in the template\n",
        "# - Clear documentation of required inputs\n",
        "# - Early error detection for typos\n",
        "# ============================================================================\n",
        "\n",
        "prompt_template = PromptTemplate(\n",
        "    template=TEMPLATE, \n",
        "    input_variables=[\"input_language\", \"output_language\"]\n",
        ")\n",
        "\n",
        "# This will work\n",
        "print(prompt_template.format(input_language=\"english\", output_language=\"german\"))\n",
        "\n",
        "# Uncommenting below would raise an error (missing variable):\n",
        "# prompt_template.format(input_language=\"english\")  # KeyError!\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üìö Few-Shot Prompting\n",
        "\n",
        "**Few-shot prompting** means providing examples in your prompt to guide the LLM's behavior. This technique:\n",
        "- Improves output consistency and quality\n",
        "- Teaches the model your expected format\n",
        "- Reduces ambiguity in complex tasks\n",
        "\n",
        "### Use Case: Sentiment Analysis with Subject Extraction"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# ZERO-SHOT PROMPT (No Examples)\n",
        "# ============================================================================\n",
        "# This template asks the LLM to analyze sentiment WITHOUT providing examples\n",
        "# It works, but the output format may be inconsistent\n",
        "# ============================================================================\n",
        "\n",
        "TEMPLATE_ZERO_SHOT = \"\"\"\n",
        "Interprete the text and evaluate the text.\n",
        "sentiment: is the text in a positive, neutral or negative sentiment?\n",
        "subject: What subject is the text about? Use exactly one word.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "sentiment\n",
        "subject\n",
        "\n",
        "text: {input}\n",
        "\"\"\"\n",
        "\n",
        "print(\"üìã Zero-shot template (no examples):\")\n",
        "print(TEMPLATE_ZERO_SHOT)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Adding Examples to Improve Quality\n",
        "\n",
        "To improve performance and consistency, we provide **examples** that show the model exactly what output format we expect. This is called **few-shot prompting**."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FEW-SHOT PROMPT (With Examples)\n",
        "# ============================================================================\n",
        "# This template includes 9 examples covering:\n",
        "# - 3 different restaurants (BellaVista, SeoulSavor, MunichMeals)\n",
        "# - 3 sentiment types each (positive, neutral, negative)\n",
        "# \n",
        "# Benefits of few-shot:\n",
        "# - Consistent output format\n",
        "# - Model learns your classification criteria\n",
        "# - Reduces hallucinations\n",
        "# ============================================================================\n",
        "\n",
        "TEMPLATE_FEW_SHOT = \"\"\"\n",
        "Interprete the text and evaluate the text.\n",
        "sentiment: is the text in a positive, neutral or negative sentiment?\n",
        "subject: What subject is the text about? Use exactly one word.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "sentiment\n",
        "subject\n",
        "\n",
        "text: {input}\n",
        "\n",
        "Examples:\n",
        "text: The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\n",
        "sentiment: positive\n",
        "subject: BellaVista\n",
        "\n",
        "text: BellaVista restaurant was alright. The food was decent, but nothing stood out.\n",
        "sentiment: neutral\n",
        "subject: BellaVista\n",
        "\n",
        "text: I was disappointed with BellaVista. The service was slow and the dishes lacked flavor.\n",
        "sentiment: negative\n",
        "subject: BellaVista\n",
        "\n",
        "text: SeoulSavor offered the most authentic Korean flavors I've tasted outside of Seoul. The kimchi was perfectly fermented and spicy.\n",
        "sentiment: positive\n",
        "subject: SeoulSavor\n",
        "\n",
        "text: SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\n",
        "sentiment: neutral\n",
        "subject: SeoulSavor\n",
        "\n",
        "text: I didn't enjoy my meal at SeoulSavor. The tteokbokki was too mushy and the service was not attentive.\n",
        "sentiment: negative\n",
        "subject: SeoulSavor\n",
        "\n",
        "text: MunichMeals has the best bratwurst and sauerkraut I've tasted outside of Bavaria. Their beer garden ambiance is truly authentic.\n",
        "sentiment: positive\n",
        "subject: MunichMeals\n",
        "\n",
        "text: MunichMeals was alright. The weisswurst was okay, but I've had better elsewhere.\n",
        "sentiment: neutral\n",
        "subject: MunichMeals\n",
        "\n",
        "text: I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\n",
        "sentiment: negative\n",
        "subject: MunichMeals\n",
        "\"\"\"\n",
        "\n",
        "print(f\"‚úÖ Few-shot template created with examples for 3 restaurants x 3 sentiments = 9 examples\")\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# USING THE FEW-SHOT TEMPLATE\n",
        "# ============================================================================\n",
        "\n",
        "prompt_template = PromptTemplate(template=TEMPLATE_FEW_SHOT, input_variables=[\"input\"])\n",
        "\n",
        "# Format with a new review to analyze\n",
        "formatted_prompt = prompt_template.format(input=\"The MunichDeals experience was just awesome!\")\n",
        "\n",
        "print(\"üìù Formatted prompt (truncated for display):\")\n",
        "print(formatted_prompt[1:300])  # Show last 200 chars to see the input"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "### Using FewShotPromptTemplate (Modular Approach)\n",
        "\n",
        "LangChain provides `FewShotPromptTemplate` for a more **structured and maintainable** way to manage examples:\n",
        "- Examples are stored as a list of dictionaries\n",
        "- Easy to add, remove, or modify examples\n",
        "- Cleaner separation of concerns"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# FEWSHOTPROMPTTEMPLATE - Modular Example Management\n",
        "# ============================================================================\n",
        "# Instead of embedding examples in a string, store them as structured data\n",
        "# This makes it easy to:\n",
        "# - Add/remove examples programmatically\n",
        "# - Load examples from a database or file\n",
        "# - Dynamically select relevant examples\n",
        "# ============================================================================\n",
        "\n",
        "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate,FewShotPromptTemplate\n",
        "\n",
        "# Examples stored as a list of dictionaries\n",
        "examples = [\n",
        "    {\n",
        "        \"text\": \"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\",\n",
        "        \"response\": \"sentiment: positive\\nsubject: BellaVista\"\n",
        "    },\n",
        "    {\n",
        "        \"text\": \"BellaVista restaurant was alright. The food was decent, but nothing stood out.\",\n",
        "        \"response\": \"sentiment: neutral\\nsubject: BellaVista\"\n",
        "    },\n",
        "    # Note: Additional examples can be added here...\n",
        "]\n",
        "\n",
        "print(f\"‚úÖ Loaded {len(examples)} examples\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# DYNAMICALLY ADDING EXAMPLES\n",
        "# ============================================================================\n",
        "# You can easily add new examples at runtime\n",
        "# ============================================================================\n",
        "\n",
        "new_example = {\n",
        "    \"text\": \"SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\",\n",
        "    \"response\": \"sentiment: neutral\\nsubject: SeoulSavor\"\n",
        "}\n",
        "examples.append(new_example)\n",
        "\n",
        "print(f\"‚úÖ Added new example. Total examples: {len(examples)}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# EXAMPLE TEMPLATE\n",
        "# ============================================================================\n",
        "# This template defines how each example will be formatted\n",
        "# The FewShotPromptTemplate will apply this to each example in the list\n",
        "# ============================================================================\n",
        "\n",
        "example_prompt = PromptTemplate(\n",
        "    input_variables=[\"text\", \"response\"], \n",
        "    template=\"Text: {text}\\n{response}\"\n",
        ")\n",
        "\n",
        "# Preview how one example looks when formatted\n",
        "print(\"üìã Example format preview:\")\n",
        "print(example_prompt.format(**examples[0]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# BUILDING THE FEWSHOTPROMPTTEMPLATE\n",
        "# ============================================================================\n",
        "# Components:\n",
        "# - examples: List of example dictionaries\n",
        "# - example_prompt: Template for formatting each example\n",
        "# - suffix: Text that comes after all examples (contains the actual input)\n",
        "# - input_variables: Variables in the suffix that need values\n",
        "# ============================================================================\n",
        "\n",
        "prompt = FewShotPromptTemplate(\n",
        "    examples=examples,           # Our list of examples\n",
        "    example_prompt=example_prompt,  # How to format each example\n",
        "    suffix=\"text: {input}\",      # The actual query (comes after examples)\n",
        "    input_variables=[\"input\"]    # Variables we need to provide\n",
        ")\n",
        "\n",
        "print(\"‚úÖ FewShotPromptTemplate created successfully!\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# VIEWING THE FINAL PROMPT\n",
        "# ============================================================================\n",
        "\n",
        "final_prompt = prompt.format(input=\"The MunichDeals experience was just awesome!\")\n",
        "\n",
        "print(\"üìù Complete Few-Shot Prompt:\")\n",
        "print(\"=\" * 60)\n",
        "print(final_prompt)\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üß† Chain-of-Thought (CoT) Prompting\n",
        "\n",
        "**Chain-of-Thought prompting** goes beyond few-shot by showing the model the **reasoning process**, not just the final answer.\n",
        "\n",
        "| Technique | Shows | Example |\n",
        "|-----------|-------|---------|\n",
        "| Few-shot | Input ‚Üí Output | \"Great food!\" ‚Üí positive |\n",
        "| Chain-of-Thought | Input ‚Üí Reasoning ‚Üí Output | \"Great food!\" ‚Üí \"expresses satisfaction\" ‚Üí positive |\n",
        "\n",
        "CoT helps with:\n",
        "- Complex reasoning tasks\n",
        "- Reducing errors\n",
        "- Making outputs more explainable"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# CHAIN-OF-THOUGHT TEMPLATE\n",
        "# ============================================================================\n",
        "# This template includes the REASONING behind each classification\n",
        "# The Q&A format guides the model through the thought process\n",
        "# ============================================================================\n",
        "\n",
        "TEMPLATE_COT = \"\"\"\n",
        "Interprete the text and evaluate the text. Determine if the text has a positive, neutral, or negative sentiment. Also, identify the subject of the text in one word.\n",
        "\n",
        "Format the output as JSON with the following keys:\n",
        "sentiment\n",
        "subject\n",
        "\n",
        "text: {input}\n",
        "\n",
        "Chain-of-Thought Prompts:\n",
        "Let's start by evaluating a statement. Consider: \"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\" How does this make you feel about BellaVista?\n",
        " It sounds like a positive review for BellaVista.\n",
        "\n",
        "Based on the positive nature of that statement, how would you format your response?\n",
        " {{ \"sentiment\": \"positive\", \"subject\": \"BellaVista\" }}\n",
        "\n",
        "Now, think about this: \"SeoulSavor was okay. The bibimbap was good but the bulgogi was a bit too sweet for my taste.\" Does this give a strong feeling either way?\n",
        " Not particularly. It seems like a mix of good and not-so-good elements, so it's neutral.\n",
        "\n",
        "Given the neutral sentiment, how should this be presented?\n",
        " {{ \"sentiment\": \"neutral\", \"subject\": \"SeoulSavor\" }}\n",
        "\n",
        "Lastly, ponder on this: \"I was let down by MunichMeals. The potato salad lacked flavor and the staff seemed uninterested.\" What's the overall impression here?\n",
        " The statement is expressing disappointment and dissatisfaction.\n",
        "\n",
        "And if you were to categorize this impression, what would it be?\n",
        " {{ \"sentiment\": \"negative\", \"subject\": \"MunichMeals\" }}\n",
        "\"\"\"\n",
        "\n",
        "print(\"‚úÖ Chain-of-Thought template created!\")\n",
        "print(\"üí° Notice how each example shows the REASONING, not just the answer.\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üîß Prompt Composition with PipelinePromptTemplate\n",
        "\n",
        "For complex prompts, you can **compose smaller templates** into a larger one. This enables:\n",
        "- **Reusability**: Use the same introduction or examples across multiple prompts\n",
        "- **Maintainability**: Update one component without touching others\n",
        "- **Flexibility**: Mix and match components for different use cases"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# PIPELINE PROMPT TEMPLATE - Composable Prompts\n",
        "# ============================================================================\n",
        "# Break a complex prompt into reusable components:\n",
        "# 1. Introduction - Task description\n",
        "# 2. Example - CoT demonstration\n",
        "# 3. Execution - The actual input to process\n",
        "# ============================================================================\n",
        "\n",
        "from langchain.prompts.pipeline import PipelinePromptTemplate\n",
        "from langchain_core.prompts import ChatPromptTemplate,PromptTemplate,FewShotPromptTemplate\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Component 1: Introduction (Task Description)\n",
        "# -----------------------------------------------------------------------------\n",
        "introduction_template = \"\"\"\n",
        "Interprete the text and evaluate the text. Determine if the text has a positive, neutral, or negative sentiment. Also, identify the subject of the text in one word.\n",
        "\"\"\"\n",
        "introduction_prompt = PromptTemplate.from_template(introduction_template)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Component 2: Example (Chain-of-Thought Demonstration)\n",
        "# -----------------------------------------------------------------------------\n",
        "example_template = \"\"\"\n",
        "Chain-of-Thought Prompts:\n",
        "Let's start by evaluating a statement. Consider: \"{example_text}\". How does this make you feel about {example_subject}?\n",
        "Response: {example_evaluation}\n",
        "\n",
        "Based on the {example_sentiment} nature of that statement, how would you format your response?\n",
        "Response: {example_format}\n",
        "\"\"\"\n",
        "example_prompt = PromptTemplate.from_template(example_template)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Component 3: Execution (The Actual Query)\n",
        "# -----------------------------------------------------------------------------\n",
        "execution_template = \"\"\"\n",
        "Now, execute this process for the text: \"{input}\".\n",
        "\"\"\"\n",
        "execution_prompt = PromptTemplate.from_template(execution_template)\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Combine Components into Final Prompt\n",
        "# -----------------------------------------------------------------------------\n",
        "full_template = \"\"\"{introduction}\n",
        "\n",
        "{example}\n",
        "\n",
        "{execution}\"\"\"\n",
        "full_prompt = PromptTemplate.from_template(full_template)\n",
        "\n",
        "# Create the pipeline\n",
        "input_prompts = [\n",
        "    (\"introduction\", introduction_prompt),\n",
        "    (\"example\", example_prompt),\n",
        "    (\"execution\", execution_prompt)\n",
        "]\n",
        "pipeline_prompt = PipelinePromptTemplate(\n",
        "    final_prompt=full_prompt, \n",
        "    pipeline_prompts=input_prompts\n",
        ")\n",
        "\n",
        "print(\"‚úÖ PipelinePromptTemplate created with 3 components!\")\n",
        "print(f\"üìã Required input variables: {pipeline_prompt.input_variables}\")\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# USING THE PIPELINE PROMPT\n",
        "# ============================================================================\n",
        "\n",
        "formatted_pipeline = pipeline_prompt.format(\n",
        "    # Example component variables\n",
        "    example_text=\"The BellaVista restaurant offers an exquisite dining experience. The flavors are rich and the presentation is impeccable.\",\n",
        "    example_subject=\"BellaVista\",\n",
        "    example_evaluation=\"It sounds like a positive review for BellaVista.\",\n",
        "    example_sentiment=\"positive\",\n",
        "    example_format='{ \"sentiment\": \"positive\", \"subject\": \"BellaVista\" }',\n",
        "    # Execution component variable\n",
        "    input=\"The new restaurant downtown has bland dishes and the wait time is too long.\"\n",
        ")\n",
        "\n",
        "print(\"üìù Composed Prompt from Pipeline:\")\n",
        "print(\"=\" * 60)\n",
        "print(formatted_pipeline)\n",
        "print(\"=\" * 60)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "---\n",
        "\n",
        "## üíæ Serializing Prompts (Save & Load)\n",
        "\n",
        "You can **save prompts to files** (YAML or JSON) and load them later. This is useful for:\n",
        "- Version control of prompts\n",
        "- Sharing prompts across projects\n",
        "- A/B testing different prompts\n",
        "\n",
        "> **Note:** `PipelinePromptTemplate` serialization is not yet fully supported."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# SAVING PROMPTS TO FILES\n",
        "# ============================================================================\n",
        "# LangChain supports YAML and JSON formats\n",
        "# ============================================================================\n",
        "\n",
        "prompt = PromptTemplate(input_variables=[\"input\"], template=\"Tell me a joke about {input}\")\n",
        "\n",
        "# Save to YAML (human-readable)\n",
        "prompt.save(\"prompt.yaml\")\n",
        "print(\"‚úÖ Saved to prompt.yaml\")\n",
        "\n",
        "# Save to JSON (easy to parse programmatically)\n",
        "prompt.save(\"prompt.json\")\n",
        "print(\"‚úÖ Saved to prompt.json\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# ============================================================================\n",
        "# LOADING PROMPTS FROM FILES\n",
        "# ============================================================================\n",
        "\n",
        "from langchain.prompts import load_prompt\n",
        "\n",
        "# Load from YAML\n",
        "prompt_yaml = load_prompt(\"prompt.yaml\")\n",
        "print(\"üìÑ Loaded from YAML:\")\n",
        "print(prompt_yaml.format(input=\"chickens\"))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": [
        "# Load from JSON\n",
        "prompt_json = load_prompt(\"prompt.json\")\n",
        "print(\"\\nüìÑ Loaded from JSON:\")\n",
        "print(prompt_json.format(input=\"cows\"))\n",
        "\n",
        "# ============================================================================\n",
        "# üìù KEY TAKEAWAYS FROM THIS NOTEBOOK:\n",
        "# ============================================================================\n",
        "# 1. PromptTemplate: Create dynamic prompts with {variables}\n",
        "# 2. Few-Shot Prompting: Include examples to guide LLM behavior\n",
        "# 3. FewShotPromptTemplate: Modular example management\n",
        "# 4. Chain-of-Thought: Show reasoning, not just answers\n",
        "# 5. PipelinePromptTemplate: Compose complex prompts from parts\n",
        "# 6. Serialization: Save/load prompts with .save() and load_prompt()\n",
        "# ============================================================================"
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 2
}
