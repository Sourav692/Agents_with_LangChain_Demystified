{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 10,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "dc651ec5-a7f0-4cfe-b4f2-18d9eb5c488c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "âœ… Environment variables loaded successfully!\n",
            "ðŸ“ Running on: Darwin\n",
            "ðŸ¤– LLM initialized: databricks-gemini-2-5-pro\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# ENVIRONMENT SETUP: Load API Keys & Import Dependencies\n",
        "# ============================================================================\n",
        "# We use python-dotenv to securely load API keys from a .env file\n",
        "# This is a best practice - never hardcode API keys in your notebooks!\n",
        "# ============================================================================\n",
        "\n",
        "from dotenv import load_dotenv\n",
        "import os\n",
        "import sys\n",
        "import platform\n",
        "\n",
        "# Load environment variables from .env file\n",
        "load_dotenv()\n",
        "\n",
        "# Add parent directory to path for importing helpers\n",
        "sys.path.append(os.path.abspath(\"../..\"))\n",
        "\n",
        "# Import our LLM factory functions\n",
        "# - get_groq_llm(): Creates a Groq-hosted LLM (fast inference with open-source models)\n",
        "# - get_openai_llm(): Creates an OpenAI GPT model\n",
        "# - get_databricks_llm(): Creates a Databricks-hosted LLM\n",
        "from helpers.utils import get_groq_llm, get_openai_llm, get_databricks_llm\n",
        "\n",
        "print(\"âœ… Environment variables loaded successfully!\")\n",
        "print(f\"ðŸ“ Running on: {platform.system()}\")\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Initialize the LLM based on platform or preference\n",
        "# The choice of LLM affects tool calling capabilities and speed\n",
        "# -----------------------------------------------------------------------------\n",
        "if sys.platform == \"win32\":\n",
        "    # Windows: Use Groq for fast inference\n",
        "    llm = get_groq_llm()\n",
        "elif sys.platform == \"darwin\":\n",
        "    # macOS: Use Databricks-hosted Gemini\n",
        "    llm = get_databricks_llm(\"databricks-gemini-2-5-pro\")  \n",
        "else:\n",
        "    # Linux: Default to Groq\n",
        "    llm = get_groq_llm()\n",
        "\n",
        "# Print which LLM we're using\n",
        "if hasattr(llm, 'model_name'):\n",
        "    print(f\"ðŸ¤– LLM initialized: {llm.model_name}\")\n",
        "elif hasattr(llm, 'model'):\n",
        "    print(f\"ðŸ¤– LLM initialized: {llm.model}\")\n",
        "else:\n",
        "    print(\"ðŸ¤– LLM initialized successfully\")"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "5e3f4601-f77c-4535-81a2-2970248c1bd5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "### Introduction of LangChain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4c1f07b6-e0a3-4efb-9b1a-b87eed7e3aef",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "The capital of France is **Paris**.\n",
            "-------------------------------------------------\n",
            "LangChain is a framework that simplifies building applications powered by large language models (LLMs) by connecting them to other data sources and tools.\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    # Note: llm is already initialized in the setup cell using helper functions\n",
        "    # The llm object is created based on your platform (Windows: Groq, macOS: Databricks, Linux: Groq)\n",
        "\n",
        "    # Get the response\n",
        "    response = llm.invoke('What is the capital of France?')\n",
        "    print(response.content)\n",
        "    \n",
        "    print(\"-------------------------------------------------\")\n",
        "    \n",
        "    # Use llm.invoke() with another question\n",
        "    alt_response = llm.invoke(\"What is LangChain? Explain in 1 line\")\n",
        "    print(alt_response.content)\n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c46bc7a5-9933-4dfb-b124-5c80b8877673",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "### First LangChain Project \n",
        "\n",
        "A LangChain pipeline is a sequence of steps where inputs are processed to produce outputs. For your first project, youâ€™ll create a basic pipeline that uses an LLM to generate text responses based on user input.\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "39546b1c-5818-4969-ad53-abc8f3c6a85c",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "Build a pipeline that: \n",
        "* Accepts a userâ€™s question as input.  \n",
        "* Uses a pre-trained LLM to generate a response.   \n",
        "* Outputs the generated text."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f15eb1c3-a4d3-4daa-9a6d-6fe6ef583bc1",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4d3c1421-93bf-40cc-a040-b387c7aeb86e",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Of course! Here is a detailed breakdown of Generative AI, covering what it is, how it works, its applications, key players, and the associated challenges.\n",
            "\n",
            "### 1. What is Generative AI?\n",
            "\n",
            "At its core, **Generative AI** is a subfield of artificial intelligence that focuses on **creating new, original content** rather than just analyzing or classifying existing data.\n",
            "\n",
            "Think of it this way:\n",
            "*   **Traditional AI (or Discriminative AI)** is like a student who learns to *classify* things. You show it thousands of pictures of cats and dogs, and it learns to tell the difference, labeling a new picture as either \"cat\" or \"dog.\"\n",
            "*   **Generative AI** is like a student who, after seeing thousands of pictures of cats, can *draw a brand new, unique picture of a cat* that has never existed before.\n",
            "\n",
            "This \"new content\" can be in various forms, including text, images, music, code, and even video.\n",
            "\n",
            "---\n",
            "\n",
            "### 2. How Does Generative AI Work?\n",
            "\n",
            "Generative AI models are trained on massive datasets of existing content (e.g., all of Wikipedia, a huge library of books, millions of images from the internet). During this training process, the model learns the underlying patterns, structures, styles, and relationships within the data.\n",
            "\n",
            "Once trained, it can use this learned knowledge to generate new content based on a user's input, known as a **prompt**.\n",
            "\n",
            "There are several key architectures and techniques used:\n",
            "\n",
            "**a) Transformers (The Engine Behind LLMs):**\n",
            "This is the most dominant architecture today, especially for text and image generation. The key innovation is the **\"attention mechanism,\"** which allows the model to weigh the importance of different words in the input text. This helps it understand context, nuance, and long-range dependencies, making its output much more coherent and relevant.\n",
            "*   **Examples:** The \"T\" in **GPT** (Generative Pre-trained Transformer) stands for Transformer. Models like Google's Gemini and Meta's Llama are also based on this architecture.\n",
            "\n",
            "**b) Diffusion Models:**\n",
            "This is the state-of-the-art technique for high-quality image generation. The process works in two steps:\n",
            "1.  **Forward Diffusion:** It takes a clear image and gradually adds \"noise\" (random pixels) until it becomes completely unrecognizable static.\n",
            "2.  **Reverse Diffusion (The Generative Part):** The model is trained to reverse this process. It learns how to start with pure noise and, guided by a text prompt (e.g., \"an astronaut riding a horse on Mars\"), it skillfully removes the noise step-by-step to \"sculpt\" a coherent image that matches the description.\n",
            "*   **Examples:** **DALL-E 3**, **Midjourney**, and **Stable Diffusion** all use this method.\n",
            "\n",
            "**c) Generative Adversarial Networks (GANs):**\n",
            "A classic and clever approach that involves two neural networks competing against each other:\n",
            "1.  **The Generator:** Tries to create fake content (e.g., a fake image of a celebrity).\n",
            "2.  **The Discriminator:** Tries to tell the difference between the real content (from the training data) and the fake content created by the Generator.\n",
            "\n",
            "They train together in a loop. The Generator gets better at making fakes, and the Discriminator gets better at spotting them. This adversarial process pushes the Generator to create incredibly realistic and high-quality content.\n",
            "*   **Examples:** GANs were foundational for early deepfakes and are still used for specific tasks like style transfer.\n",
            "\n",
            "---\n",
            "\n",
            "### 3. What Can Generative AI Create? (Key Applications)\n",
            "\n",
            "Generative AI is not a single tool but a category of technologies with diverse applications:\n",
            "\n",
            "*   **Text Generation:**\n",
            "    *   **Conversational AI:** Powering chatbots and virtual assistants like **ChatGPT**, **Google Gemini**, and **Anthropic's Claude**.\n",
            "    *   **Content Creation:** Writing articles, marketing copy, emails, and social media posts.\n",
            "    *   **Summarization:** Condensing long documents or articles into key points.\n",
            "    *   **Translation:** Translating languages with more nuance and context.\n",
            "\n",
            "*   **Code Generation:**\n",
            "    *   Writing code snippets, functions, or even entire programs based on natural language descriptions.\n",
            "    *   **Examples:** **GitHub Copilot**, which is integrated into coding environments.\n",
            "\n",
            "*   **Image Generation:**\n",
            "    *   Creating original artwork, illustrations, and logos from text prompts.\n",
            "    *   Generating photorealistic images for advertising, design, and entertainment.\n",
            "    *   **Examples:** **Midjourney**, **DALL-E 3**, **Stable Diffusion**.\n",
            "\n",
            "*   **Audio and Music Generation:**\n",
            "    *   Composing original music in various genres.\n",
            "    *   Creating realistic voiceovers and text-to-speech (voice synthesis).\n",
            "    *   Generating sound effects for games and films.\n",
            "\n",
            "*   **Video Generation:**\n",
            "    *   The newest frontier, creating short video clips from text prompts.\n",
            "    *   **Examples:** **OpenAI's Sora**, **RunwayML**, **Pika Labs**.\n",
            "\n",
            "*   **Synthetic Data Generation:**\n",
            "    *   Creating artificial data to train other AI models, especially in fields where real-world data is scarce or private (e.g., medical records, financial data).\n",
            "\n",
            "---\n",
            "\n",
            "### 4. Major Players and Models\n",
            "\n",
            "*   **OpenAI:** A leader in the field, known for the **GPT** series (GPT-3, GPT-4), **ChatGPT**, image generator **DALL-E**, and video generator **Sora**.\n",
            "*   **Google (and DeepMind):** A major research powerhouse with its **Gemini** family of models (Ultra, Pro, Nano), which power its chatbot (formerly Bard). Also developed image models like **Imagen**.\n",
            "*   **Meta (Facebook):** Focuses heavily on open-source models, most notably the **Llama** series, which has spurred massive innovation in the developer community.\n",
            "*   **Anthropic:** Founded by former OpenAI employees with a strong focus on AI safety. Their main model is **Claude**.\n",
            "*   **Stability AI:** Champions of open-source models, primarily known for **Stable Diffusion**, which democratized high-quality image generation.\n",
            "*   **Midjourney:** An independent, self-funded research lab focused exclusively on its highly artistic and stylized image generation tool.\n",
            "\n",
            "---\n",
            "\n",
            "### 5. Benefits and Advantages\n",
            "\n",
            "*   **Increased Productivity and Efficiency:** Automates repetitive tasks like writing emails, summarizing reports, or generating code.\n",
            "*   **Enhanced Creativity:** Acts as a co-pilot for artists, designers, and writers, helping them brainstorm and overcome creative blocks.\n",
            "*   **Personalization:** Enables hyper-personalized experiences in marketing, education, and entertainment.\n",
            "*   **Accessibility:** Lowers the barrier to entry for creating professional-quality content, code, and art.\n",
            "\n",
            "---\n",
            "\n",
            "### 6. Risks and Challenges\n",
            "\n",
            "*   **Hallucinations and Inaccuracy:** Models can confidently generate false or nonsensical information. Fact-checking is crucial.\n",
            "*   **Bias:** Since models are trained on internet data, they can inherit and amplify existing societal biases related to race, gender, and culture.\n",
            "*   **Ethical Concerns:**\n",
            "    *   **Misinformation & Disinformation:** The potential to create realistic fake news, images (deepfakes), and propaganda at scale.\n",
            "    *   **Job Displacement:** The automation of creative and analytical jobs is a significant concern.\n",
            "    *   **Copyright and Ownership:** Who owns AI-generated content? Can models be trained on copyrighted material without permission? These are active legal battles.\n",
            "*   **Security Risks:** Malicious actors can use AI for phishing, creating malware, or finding security vulnerabilities.\n",
            "*   **Environmental and Financial Cost:** Training large models requires immense computational power, which consumes vast amounts of energy and costs millions of dollars.\n",
            "-------------------------------------------------\n",
            "[{\"type\": \"text\", \"text\": \"Of course! Here is a detailed breakdown of Deep Learning, structured to be understandable for a beginner but comprehensive enough for someone looking for depth.\\n\\n---\\n\\n### What is Deep Learning? A Simple Analogy\\n\\nAt its core, **Deep Learning is a subfield of Machine Learning that uses algorithms inspired by the structure and function of the human brain.** These algorithms are called **Artificial Neural Networks (ANNs)**.\\n\\nImagine you're teaching a toddler to recognize a cat. You don't give them a list of rules like \\\"if it has pointy ears, whiskers, and a tail, it's a cat.\\\" Instead, you just show them many, many pictures of cats. Over time, their brain automatically learns the features\\u2014the patterns, shapes, and textures\\u2014that define a \\\"cat.\\\"\\n\\nDeep Learning works in a very similar way. You feed a deep learning model a massive amount of data (e.g., thousands of cat images), and it learns to recognize the patterns on its own.\\n\\nThe key difference from traditional Machine Learning is this **automatic feature extraction**. In traditional ML, a human expert would have to manually program the features (e.g., \\\"measure ear pointiness,\\\" \\\"count whiskers\\\"). In Deep Learning, the network learns these features by itself, from the raw data.\\n\\n### How Does It Work? The Core Concepts\\n\\nDeep Learning is built on the concept of Artificial Neural Networks. Let's break that down.\\n\\n#### 1. The Neuron (or Node)\\nThis is the most basic unit. A neuron receives one or more inputs, performs a simple mathematical operation, and produces an output.\\n*   **Inputs:** Data points (e.g., the pixel values of an image).\\n*   **Weights:** Each input is multiplied by a \\\"weight.\\\" This weight signifies the importance of that input. The network *learns* by adjusting these weights.\\n*   **Bias:** An extra number that is added to the mix, allowing the model to make adjustments that are independent of the inputs.\\n*   **Activation Function:** The final sum is passed through an activation function, which decides whether the neuron should \\\"fire\\\" (be activated) and what its output should be. This introduces non-linearity, allowing the network to learn complex patterns.\\n\\n\"}, {\"type\": \"text\", \"text\": \"\\n\\n#### 2. Layers of Neurons\\nA single neuron isn't very powerful. The magic happens when you stack them in layers:\\n*   **Input Layer:** Receives the initial raw data (e.g., all the pixels of an image).\\n*   **Hidden Layers:** These are the layers between the input and output. This is where the real \\\"thinking\\\" happens. The network processes the data through these layers, with the output of one layer becoming the input for the next.\\n*   **Output Layer:** Produces the final result (e.g., a probability that the image is a \\\"cat\\\" or a \\\"dog\\\").\\n\\n#### 3. The \\\"Deep\\\" in Deep Learning\\nA neural network is considered \\\"deep\\\" when it has **multiple hidden layers** (from a few to hundreds).\\n\\nThis depth allows the network to learn a **hierarchy of features**.\\n*   **Layer 1** might learn to recognize simple edges and colors.\\n*   **Layer 2** might combine those edges to recognize shapes like eyes, ears, and noses.\\n*   **Layer 3** might combine those shapes to recognize a cat's face.\\n*   **Deeper Layers** combine these features to recognize the concept of a \\\"cat\\\" in various poses and environments.\\n\\n\"}, {\"type\": \"text\", \"text\": \"\\n\\n### The Learning Process: Training a Model\\n\\nHow does the network \\\"learn\\\" the correct weights? Through a process called **training**.\\n\\n1.  **Forward Propagation:** You feed the network an input (e.g., a cat image). The data flows forward through the layers, and the network makes a prediction (e.g., it says \\\"dog\\\" with 80% confidence).\\n2.  **Loss Function (Error Calculation):** You compare the network's prediction (\\\"dog\\\") to the actual label (\\\"cat\\\"). A **loss function** calculates a score representing how wrong the prediction was. A high score means a big error.\\n3.  **Backpropagation & Optimization:** This is the crucial step. The network uses an algorithm called **backpropagation** to work backward from the error. It figures out which weights in the network contributed most to the error. Then, an **optimizer** (like \\\"Gradient Descent\\\") makes tiny adjustments to those weights to reduce the error.\\n4.  **Repeat:** This process is repeated millions of times with all the data in your dataset. With each cycle, the network's weights are fine-tuned, and its predictions become more and more accurate.\\n\\n### Why is Deep Learning So Popular Now?\\n\\nNeural networks have been around since the 1950s. Their recent explosion in popularity is due to a perfect storm of three factors:\\n\\n1.  **Big Data:** The internet age has produced massive datasets (e.g., ImageNet, Wikipedia, YouTube) that are essential for training deep models.\\n2.  **Powerful Hardware (GPUs):** The math behind deep learning involves a huge number of matrix multiplications. **Graphics Processing Units (GPUs)**, originally designed for video games, are incredibly efficient at performing these calculations in parallel, reducing training time from months to days or even hours.\\n3.  **Algorithmic Improvements:** Researchers have developed better network architectures, activation functions (like ReLU), and optimization algorithms (like Adam) that make training deep networks more stable and effective.\\n\\n### Key Deep Learning Architectures\\n\\nDifferent problems require different types of network structures. The three most famous are:\\n\\n1.  **Convolutional Neural Networks (CNNs):**\\n    *   **Best for:** Image and video analysis.\\n    *   **How it works:** Uses special layers with \\\"filters\\\" (or kernels) that slide across an image to detect specific features like edges, textures, and shapes, regardless of where they are in the image. This makes them highly effective for visual tasks.\\n    *   **Examples:** Facial recognition, self-driving car perception, medical image analysis (e.g., detecting tumors in X-rays).\\n\\n2.  **Recurrent Neural Networks (RNNs):**\\n    *   **Best for:** Sequential data, where order matters.\\n    *   **How it works:** Has a \\\"memory\\\" loop. The output from a previous step is fed back as an input to the current step. This allows it to understand context and sequence. Variants like **LSTM** and **GRU** have more sophisticated memory to handle long-term dependencies.\\n    *   **Examples:** Natural Language Processing (NLP), machine translation, speech recognition, stock market prediction.\\n\\n3.  **Transformers:**\\n    *   **Best for:** Natural Language Processing (the current state-of-the-art).\\n    *   **How it works:** Uses a mechanism called **\\\"self-attention\\\"** to weigh the importance of all other words in a sentence when processing a single word. Unlike RNNs, it can process the entire sequence at once, making it highly parallelizable and powerful.\\n    *   **Examples:** **GPT-3 & GPT-4** (the model behind ChatGPT), Google's BERT, advanced machine translation.\\n\\n### Advantages and Limitations\\n\\n| Advantages                               | Limitations                                      |\\n| ---------------------------------------- | ------------------------------------------------ |\\n| **State-of-the-Art Performance:** Achieves the best results on many complex problems (vision, NLP). | **Data Hungry:** Requires massive amounts of labeled data to perform well. |\\n| **Automatic Feature Engineering:** Saves immense time and effort by learning features directly from data. | **Computationally Expensive:** Training requires powerful and costly hardware (GPUs/TPUs). |\\n| **Handles Unstructured Data:** Excels at processing data like images, text, and sound. | **\\\"Black Box\\\" Problem:** It can be very difficult to understand *why* a deep learning model made a particular decision (interpretability). |\\n| **Highly Flexible:** Can be adapted to solve a wide variety of problems. | **Prone to Overfitting:** Can memorize the training data instead of generalizing, if not carefully regularized. |\\n\\n---\\n\\nIn summary, Deep Learning is a powerful and transformative technology that allows machines to learn complex patterns from vast amounts of data, enabling breakthroughs in everything from how we interact with technology to how we diagnose diseases.\"}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/LangChain_Demystified/.venv/lib/python3.13/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [field_name='content', input_value=[{'type': 'text', 'text':...we diagnose diseases.'}], input_type=list])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ],
      "source": [
        "try:\n",
        "    \n",
        "    # Step 1: Create a Prompt Template\n",
        "    prompt = PromptTemplate(\n",
        "        input_variables=['topic'],\n",
        "        template=\"Provide me details about {topic}?\"\n",
        "    )\n",
        "\n",
        "    # Step 2: Create a Chain using LCEL (LangChain Expression Language)\n",
        "    # The | operator chains: prompt -> llm -> output parser\n",
        "    chain = prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Step 3: Generate the response\n",
        "    response = chain.invoke({'topic': 'Generative AI'})\n",
        "    resp = chain.invoke({'topic': 'Deep Learning'})\n",
        "    \n",
        "    print(response)\n",
        "    print(\"-------------------------------------------------\")\n",
        "    print(resp)\n",
        "    \n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "0bc02a62-48bd-449b-82fe-8e97663f527a",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "### Modify the above project\n",
        "* After generating the response, summarize it into a shorter version."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "8f4690bf-6a59-4ef5-9215-d965a4714d45",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/LangChain_Demystified/.venv/lib/python3.13/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [field_name='content', input_value=[{'type': 'text', 'text':...ot trained carefully.'}], input_type=list])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Deep Learning is a machine learning technique that uses multi-layered artificial neural networks, inspired by the human brain, to automatically learn complex patterns and features from vast amounts of data.\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "from langchain_core.runnables import RunnablePassthrough\n",
        "\n",
        "try:\n",
        "    \n",
        "    # Step 1: Create Prompt Templates\n",
        "    detail_prompt = PromptTemplate(\n",
        "        input_variables=['topic'],\n",
        "        template=\"Provide me details about {topic}?\"\n",
        "    )\n",
        "\n",
        "    summary_prompt = PromptTemplate(\n",
        "        input_variables=['text'],\n",
        "        template=\"Summarize the following text into a single concise sentence: {text}\"\n",
        "    )\n",
        "\n",
        "    # Step 2: Create individual chains using LCEL\n",
        "    answer_chain = detail_prompt | llm | StrOutputParser()\n",
        "    summary_chain = summary_prompt | llm | StrOutputParser()\n",
        "\n",
        "    # Step 3: Combine the Chains using LCEL\n",
        "    # First chain generates details, then passes to summary chain\n",
        "    pipeline = (\n",
        "        {\"topic\": RunnablePassthrough()}\n",
        "        | answer_chain\n",
        "        | (lambda text: {\"text\": text})\n",
        "        | summary_chain\n",
        "    )\n",
        "\n",
        "    # Step 4: Generate the Response\n",
        "    response = pipeline.invoke('Deep Learning')\n",
        "\n",
        "    print(response)\n",
        "        \n",
        "    \n",
        "except Exception as e:\n",
        "    print(e)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "ddd8ba57-330a-4583-9a7e-26f90244ae62",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "### Add a Sentiment Analysis Step at the end"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "4d8f7865-ea5f-4a0b-8790-fefc0f03f0e5",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Based on the text provided, the sentiment is **Neutral**.\n",
            "\n",
            "**Analysis:**\n",
            "\n",
            "The text is purely informational and descriptive. It defines Deep Learning in a factual, objective manner, explaining its inspiration, what it is, and how it works. There are no words or phrases that express a positive or negative opinion, emotion, or judgment.\n"
          ]
        }
      ],
      "source": [
        "# Create a sentiment analysis prompt\n",
        "sentiment_prompt = PromptTemplate(\n",
        "    input_variables=['text'],\n",
        "    template=\"Analyze the sentiment of the following text: {text}\"\n",
        ")\n",
        "\n",
        "# Create the sentiment chain\n",
        "sentiment_chain = sentiment_prompt | llm | StrOutputParser()\n",
        "\n",
        "# Combine all three chains: details -> summary -> sentiment\n",
        "full_pipeline = (\n",
        "    {\"topic\": RunnablePassthrough()}\n",
        "    | answer_chain\n",
        "    | (lambda text: {\"text\": text})\n",
        "    | summary_chain\n",
        "    | (lambda text: {\"text\": text})\n",
        "    | sentiment_chain\n",
        ")\n",
        "\n",
        "response = full_pipeline.invoke('Deep Learning')\n",
        "\n",
        "print(response)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "c761b6d4-cf34-4863-ab87-c5ab7041f912",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "source": [
        "### Add a Dynamic User Input Chain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "f15a4378-0cdb-42b9-96ea-0f3818031e74",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "\n",
            "\u001b[1m> Entering new LLMChain chain...\u001b[0m\n",
            "Prompt after formatting:\n",
            "\u001b[32;1m\u001b[1;3mProvide me details about Deep Learning?\u001b[0m\n",
            "\n",
            "\u001b[1m> Finished chain.\u001b[0m\n",
            "\n",
            "\n",
            "Deep learning is a subset of machine learning that utilizes artificial neural networks to learn and make decisions from data. It is a form of artificial intelligence that mimics the way the human brain processes information. \n",
            "\n",
            "In deep learning, the neural networks have multiple layers of interconnected nodes that can process and transform data at each layer. The layers are organized in a hierarchical manner, with each layer learning progressively more abstract features from the input data. The final layer produces an output that can be used for decision making or prediction.\n",
            "\n",
            "One of the main advantages of deep learning is its ability to automatically extract features from raw data, eliminating the need for manual feature engineering. This makes it suitable for handling large and complex datasets.\n",
            "\n",
            "Some common applications of deep learning include image and speech recognition, natural language processing, and self-driving cars. It has also been used in various industries such as healthcare, finance, and marketing to analyze and make predictions from large amounts of data.\n",
            "\n",
            "However, deep learning also has some limitations, such as the need for large amounts of data for training and the potential for overfitting. It also requires significant computational power and resources for training and running the models.\n",
            "\n",
            "Overall, deep learning has shown promising results in various fields and continues to advance as more research is being conducted in this area.\n",
            "Exiting the assistant.GoodBye!!\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.prompts import PromptTemplate\n",
        "from langchain_core.output_parsers import StrOutputParser\n",
        "\n",
        "# Step 1: Create Prompt Template\n",
        "detail_prompt = PromptTemplate(\n",
        "    input_variables=['topic'],\n",
        "    template=\"Provide me details about {topic}?\"\n",
        ")\n",
        "\n",
        "# Step 2: Create the chain using LCEL\n",
        "answer_chain = detail_prompt | llm | StrOutputParser()\n",
        "\n",
        "while True:\n",
        "    user_input = input(\"Enter the topic you want to know more about (or type 'exit' to quit): \")\n",
        "    \n",
        "    # Exit the loop if the user types 'exit'\n",
        "    if user_input.lower() == 'exit':\n",
        "        print(\"Exiting the assistant. GoodBye!!\")\n",
        "        break\n",
        "    \n",
        "    response = answer_chain.invoke({'topic': user_input})\n",
        "    print(response)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 0,
      "metadata": {
        "application/vnd.databricks.v1+cell": {
          "cellMetadata": {},
          "inputWidgets": {},
          "nuid": "110563cf-cd75-4f6f-9f00-1fe3b6c9ff95",
          "showTitle": false,
          "tableResultSettingsMap": {},
          "title": ""
        }
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "application/vnd.databricks.v1+notebook": {
      "computePreferences": null,
      "dashboards": [],
      "environmentMetadata": null,
      "language": "python",
      "notebookMetadata": {},
      "notebookName": "1. Introduction",
      "widgets": {}
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
