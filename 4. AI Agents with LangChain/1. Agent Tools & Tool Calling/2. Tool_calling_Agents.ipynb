{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "f25fd369",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "LLM helpers imported successfully!\n",
            "LLM initialized: databricks-gemini-2-5-pro (Databricks)\n"
          ]
        }
      ],
      "source": [
        "# ============================================================================\n",
        "# SETUP: Import LLM Helper Functions\n",
        "# ============================================================================\n",
        "# We use helper functions to create LLM instances with proper configuration\n",
        "# These functions handle API key loading and model configuration\n",
        "\n",
        "import os\n",
        "import sys\n",
        "\n",
        "# Add parent directory to path for importing helpers\n",
        "sys.path.append(os.path.abspath(\"../..\"))\n",
        "\n",
        "# Import our LLM factory functions\n",
        "# - get_groq_llm(): Creates a Groq-hosted LLM (fast inference)\n",
        "# - get_openai_llm(): Creates an OpenAI GPT model\n",
        "from helpers.utils import get_groq_llm, get_openai_llm,get_databricks_llm\n",
        "\n",
        "print(\"LLM helpers imported successfully!\")\n",
        "\n",
        "# ============================================================================\n",
        "# CREATE THE LLM AND CHATBOT GRAPH\n",
        "# ============================================================================\n",
        "\n",
        "# -----------------------------------------------------------------------------\n",
        "# Step 1: Initialize the LLM\n",
        "# We use Groq for fast inference, but you can swap to OpenAI\n",
        "# -----------------------------------------------------------------------------\n",
        "llm = get_databricks_llm(\"databricks-gemini-2-5-pro\")  # Fast, open-source models hosted by Groq\n",
        "# Alternative: llm = get_openai_llm()  # OpenAI's GPT models\n",
        "\n",
        "if hasattr(llm, 'model_name'):\n",
        "    print(f\"LLM initialized: {llm.model_name}\")\n",
        "elif hasattr(llm, 'model'):\n",
        "    print(f\"LLM initialized: {llm.model} (Databricks)\")\n",
        "else:\n",
        "    print(\"LLM initialized: Groq LLM\")"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "c860320d",
      "metadata": {},
      "source": [
        "## Basic Tool Calling Example"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "08d5f82f",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{'name': 'get_weather', 'args': {'city': 'Bangalore'}, 'id': 'get_weather', 'type': 'tool_call'}]\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain_core.messages import HumanMessage\n",
        "\n",
        "# Define custom tools\n",
        "@tool\n",
        "def get_weather(city: str) -> str:\n",
        "    \"\"\"Get the current weather for a given city.\"\"\"\n",
        "    # Simulated weather data\n",
        "    weather_data = {\n",
        "        \"bangalore\": \"28°C, Partly Cloudy\",\n",
        "        \"mumbai\": \"32°C, Humid\",\n",
        "        \"delhi\": \"25°C, Sunny\"\n",
        "    }\n",
        "    return weather_data.get(city.lower(), \"Weather data not available\")\n",
        "\n",
        "@tool\n",
        "def calculate(expression: str) -> str:\n",
        "    \"\"\"Evaluate a mathematical expression.\"\"\"\n",
        "    try:\n",
        "        result = eval(expression)\n",
        "        return f\"Result: {result}\"\n",
        "    except Exception as e:\n",
        "        return f\"Error: {str(e)}\"\n",
        "\n",
        "# Bind tools to the LLM\n",
        "tools = [get_weather, calculate]\n",
        "llm_with_tools = llm.bind_tools(tools)\n",
        "\n",
        "# Invoke with a query\n",
        "response = llm_with_tools.invoke(\"What's the weather in Bangalore?\")\n",
        "print(response.tool_calls)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "5c4e19f4",
      "metadata": {},
      "source": [
        "## Complete Agent Example with Tool Execution"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "55397909",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"type\": \"text\", \"text\": \"I can get you the stock price, but I need to know which stock symbol you're interested in (for example, GOOGL).\", \"thoughtSignature\": \"CvQIAY89a1/IIO9cOWUxPzqtCyINA5JSu+cEOJIAClPGxpUpkaAtIoTwR3HVyvnhwDd/fnAIjQvPu5hioIbBUSK9Jd40LtRrUmpSGIrd6MRXosDTSasoP7z9Ybs5rEKPOOVLvBjcnUsslamx7Q+JiIRqlhIlfGMgnG1HkyzHHc0LCxSwP0bk2Fk7s5YypYy7zBU7w856yf5jgXaLOB2JyrvKhezjI+iECVMH7ZQVfWXU02kjw5KmBQpFVo1XJPIFPx7/oHM18iH3N58bz89s0nR/iTL3cxuXX5reVZ2nJAzNoiMMN9KrY5rOBTkUUmZLdDW11mebq+eJiFuQNnuOFLxgR7Hum8mhqFD70OdiUc9sN2kMOiQlbgvejQNbpaUR3jZBCGKilBJYGzrUP4YVJgzxQKZgs8DwOjSV5HcBA1szx3py/ERqqyychOkhWMTkM4RmVOJzGs1AXuT2foDbSZMqg7Nzq5147nNdW440DMeJZcbeIkyTwj1HG4yQQjZOlc51hTJvq/Ats92f5To7wK5SdsbQX1yr2PI9KLOnEIwPTjAD4P+IgOgDM8ctcz8e38+kX1crTljLauhrfZhVMRlyOSc253JDu4IKFITfg/WRQ1GIZv9fAqCmeUZILHtkE9OMiNLVDvwa0lI3OqkhZIhrjHKHWvgax7/Jrk7G+AMcmcLWB74krfL3bhD49f4PpROyhlFmKsGYs8MRNr0yBKMPcVD2ndYB4JErEJmBNqM1RoQLT54y4SDRpuEx/gkiaW0lWMvVZW7q0++eq4NAgblbKAhY8dZeKp6My3SYqXFDDjMnJCNcOIt0rw5BhNYiDVm0b162kqg4alXSyVMDvPw964ol1zFefoxYwSI64VaLxazRBheTXMUleDNUGpgTNpGV4ZcS5Oq/NdJS+EVICxtzb6jJ7trBZbcUnFjJ6fc0rZKhGmMXi/dIoqXBfqeUD1JCptQ1Ce9ASjMDjPUzrWxpcRcwmWCfMBz//UItwDMJ9G7wvGSNtGKWTydIdQuIb8ENMKjTxHyB+flaF6KUx4ZnvTzJRXP7gYTghASnA/SZJEclhgW/bwu57ala1PPtwUHTYNsJDdAcCgYIEeMLaArox2i2vg5VyavySEqifAeNl9yaGKZnU8oCDCsh8KyR0d6dptwBmvgOom7o5JN4UjVxdbySQkmECqAcGRo7e91JGylFy2Z9FuUrJd12q/tYwqukq89Ma7OyvrRbfvcXooWtgJnIF2lDFvMoQzf3yPc89bdyRTKcMXhrYV9GDWThwvwLCwL8emB0IRe3S9lHk3hEf/6iQ6X71mIZrbQ1HnAWyTv9WPVzu36R9XnjBu6MMqbW8y2d4Gh11GQ538Q4WqDvBBuUjXe4rdnNcIgWCzZB3wc75uh9033ZoBKxJe0nzfPwwxIihLD6nFNU3KTdTKGTTRbPFNxwHT1W1DXQhUyW7YSFr3WMXZMOt8+ki9bzJAi9f2oW+CqLLUJI3SJyF2sAjl/bzft9x13KrJXoaGjzY/7+QIkH\"}]\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/Users/sourav.banerjee/Documents/Codebases/2. AI ENGINEERING/LangChain_Demystified/.venv/lib/python3.13/site-packages/pydantic/main.py:464: UserWarning: Pydantic serializer warnings:\n",
            "  PydanticSerializationUnexpectedValue(Expected `str` - serialized value may not be as expected [field_name='content', input_value=[{'type': 'text', 'text':...9x13KrJXoaGjzY/7+QIkH'}], input_type=list])\n",
            "  return self.__pydantic_serializer__.to_python(\n"
          ]
        }
      ],
      "source": [
        "from langchain_core.tools import tool\n",
        "from langchain.agents import create_agent\n",
        "\n",
        "# Define tools\n",
        "@tool\n",
        "def search_database(query: str) -> str:\n",
        "    \"\"\"Search the database for information about a topic.\"\"\"\n",
        "    return f\"Found 3 results for: {query}\"\n",
        "\n",
        "@tool\n",
        "def get_stock_price(symbol: str) -> str:\n",
        "    \"\"\"Get the current stock price for a given symbol.\"\"\"\n",
        "    prices = {\"GOOGL\": 175.50, \"MSFT\": 420.30, \"AAPL\": 195.80}\n",
        "    price = prices.get(symbol.upper(), \"Not found\")\n",
        "    return f\"{symbol.upper()}: ${price}\"\n",
        "\n",
        "@tool\n",
        "def send_email(to: str, subject: str, body: str) -> str:\n",
        "    \"\"\"Send an email to the specified recipient.\"\"\"\n",
        "    return f\"Email sent to {to} with subject: {subject}\"\n",
        "\n",
        "tools = [search_database, get_stock_price, send_email]\n",
        "\n",
        "# Create agent using the new LangChain 1.x API\n",
        "# create_agent returns a compiled graph that can be invoked directly\n",
        "agent = create_agent(\n",
        "    model=llm,\n",
        "    tools=tools,\n",
        "    system_prompt=\"You are a helpful assistant. Use tools when needed.\"\n",
        ")\n",
        "\n",
        "# Run the agent\n",
        "# The new API uses \"messages\" as input instead of \"input\"\n",
        "result = agent.invoke({\n",
        "    \"messages\": [{\"role\": \"user\", \"content\": \"What's the stock price of Google?\"}]\n",
        "})\n",
        "\n",
        "# Extract the final response\n",
        "final_message = result[\"messages\"][-1]\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "id": "5c667aeb",
      "metadata": {},
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "[{\"type\": \"text\", \"text\": \"I can get you the stock price, but I need to know which stock symbol you're interested in (for example, GOOGL).\", \"thoughtSignature\": \"CvQIAY89a1/IIO9cOWUxPzqtCyINA5JSu+cEOJIAClPGxpUpkaAtIoTwR3HVyvnhwDd/fnAIjQvPu5hioIbBUSK9Jd40LtRrUmpSGIrd6MRXosDTSasoP7z9Ybs5rEKPOOVLvBjcnUsslamx7Q+JiIRqlhIlfGMgnG1HkyzHHc0LCxSwP0bk2Fk7s5YypYy7zBU7w856yf5jgXaLOB2JyrvKhezjI+iECVMH7ZQVfWXU02kjw5KmBQpFVo1XJPIFPx7/oHM18iH3N58bz89s0nR/iTL3cxuXX5reVZ2nJAzNoiMMN9KrY5rOBTkUUmZLdDW11mebq+eJiFuQNnuOFLxgR7Hum8mhqFD70OdiUc9sN2kMOiQlbgvejQNbpaUR3jZBCGKilBJYGzrUP4YVJgzxQKZgs8DwOjSV5HcBA1szx3py/ERqqyychOkhWMTkM4RmVOJzGs1AXuT2foDbSZMqg7Nzq5147nNdW440DMeJZcbeIkyTwj1HG4yQQjZOlc51hTJvq/Ats92f5To7wK5SdsbQX1yr2PI9KLOnEIwPTjAD4P+IgOgDM8ctcz8e38+kX1crTljLauhrfZhVMRlyOSc253JDu4IKFITfg/WRQ1GIZv9fAqCmeUZILHtkE9OMiNLVDvwa0lI3OqkhZIhrjHKHWvgax7/Jrk7G+AMcmcLWB74krfL3bhD49f4PpROyhlFmKsGYs8MRNr0yBKMPcVD2ndYB4JErEJmBNqM1RoQLT54y4SDRpuEx/gkiaW0lWMvVZW7q0++eq4NAgblbKAhY8dZeKp6My3SYqXFDDjMnJCNcOIt0rw5BhNYiDVm0b162kqg4alXSyVMDvPw964ol1zFefoxYwSI64VaLxazRBheTXMUleDNUGpgTNpGV4ZcS5Oq/NdJS+EVICxtzb6jJ7trBZbcUnFjJ6fc0rZKhGmMXi/dIoqXBfqeUD1JCptQ1Ce9ASjMDjPUzrWxpcRcwmWCfMBz//UItwDMJ9G7wvGSNtGKWTydIdQuIb8ENMKjTxHyB+flaF6KUx4ZnvTzJRXP7gYTghASnA/SZJEclhgW/bwu57ala1PPtwUHTYNsJDdAcCgYIEeMLaArox2i2vg5VyavySEqifAeNl9yaGKZnU8oCDCsh8KyR0d6dptwBmvgOom7o5JN4UjVxdbySQkmECqAcGRo7e91JGylFy2Z9FuUrJd12q/tYwqukq89Ma7OyvrRbfvcXooWtgJnIF2lDFvMoQzf3yPc89bdyRTKcMXhrYV9GDWThwvwLCwL8emB0IRe3S9lHk3hEf/6iQ6X71mIZrbQ1HnAWyTv9WPVzu36R9XnjBu6MMqbW8y2d4Gh11GQ538Q4WqDvBBuUjXe4rdnNcIgWCzZB3wc75uh9033ZoBKxJe0nzfPwwxIihLD6nFNU3KTdTKGTTRbPFNxwHT1W1DXQhUyW7YSFr3WMXZMOt8+ki9bzJAi9f2oW+CqLLUJI3SJyF2sAjl/bzft9x13KrJXoaGjzY/7+QIkH\"}]\n"
          ]
        }
      ],
      "source": [
        "print(final_message.content)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "id": "f593fb07",
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.11"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 5
}
