{
    "cells": [
        {
            "cell_type": "markdown",
            "id": "header-cell",
            "metadata": {},
            "source": [
                "# Intelligent Travel Assistant - LangChain Agent Assignment\n",
                "\n",
                "## üéØ Assignment Objectives\n",
                "\n",
                "In this assignment, you will build an **Intelligent Travel Assistant** that can:\n",
                "1. **Search for local attractions** in any destination the user specifies\n",
                "2. **Fetch current weather** for the destination\n",
                "3. **Provide travel-ready information** combining both data sources\n",
                "\n",
                "## üìã What You'll Practice\n",
                "- Creating custom tools with the `@tool` decorator\n",
                "- Building a Tool-Calling Agent using `create_tool_calling_agent`\n",
                "- Using `AgentExecutor` to run the agent\n",
                "- Designing system prompts for specific use cases\n",
                "\n",
                "## üèóÔ∏è Architecture\n",
                "\n",
                "```\n",
                "User Query: \"Tell me about Kolkata\"\n",
                "              ‚îÇ\n",
                "              ‚ñº\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ         Travel Assistant Agent          ‚îÇ\n",
                "‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§\n",
                "‚îÇ  System Prompt: ReAct pattern for       ‚îÇ\n",
                "‚îÇ  travel queries + weather info          ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "              ‚îÇ\n",
                "    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "    ‚ñº                   ‚ñº\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ Web Search ‚îÇ    ‚îÇ  Weather   ‚îÇ\n",
                "‚îÇ   Tool     ‚îÇ    ‚îÇ   Tool     ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "    ‚îÇ                   ‚îÇ\n",
                "    ‚ñº                   ‚ñº\n",
                "‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê\n",
                "‚îÇ Tavily API‚îÇ    ‚îÇ WeatherAPI  ‚îÇ\n",
                "‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò\n",
                "```"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "991a2742",
            "metadata": {},
            "source": [
                "### **Complete Execution Workflow** :\n",
                "\n",
                "1. **Input Reception** : User query received\n",
                "2. **Agent Initialization** : ReAct agent starts reasoning loop\n",
                "3. **Thought Process** : LLM analyzes what information is needed\n",
                "4. **Tool Selection** : Chooses appropriate tools (search_web_extract_info, get_weather)\n",
                "5. **Action Execution** : Calls selected tools with proper inputs\n",
                "6. **Result Processing** : Processes tool outputs\n",
                "7. **Iteration Decision** : Determines if more actions are needed\n",
                "8. **Loop Continuation** : Repeats until sufficient information gathered\n",
                "9. **Final Synthesis** : Combines all information into comprehensive answer\n",
                "10. **Response Formatting** : Displays both full reasoning and final answer\n"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section1-header",
            "metadata": {},
            "source": [
                "---\n",
                "## üîß Section 1: Environment Setup"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "install-deps",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# INSTALL DEPENDENCIES (Run once, then comment out)\n",
                "# =============================================================================\n",
                "# Uncomment these lines if you need to install the packages:\n",
                "\n",
                "# !pip install -qq langchain==0.3.14\n",
                "# !pip install -qq langchain-openai==0.3.0\n",
                "# !pip install -qq langchain-community==0.3.14\n",
                "# !pip install -qq markitdown"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "load-env",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# LOAD ENVIRONMENT VARIABLES\n",
                "# =============================================================================\n",
                "# Your .env file should contain:\n",
                "#   OPENAI_API_KEY=your_openai_key\n",
                "#   TAVILY_API_KEY=your_tavily_key\n",
                "#   WEATHER_API_KEY=your_weatherapi_key (from weatherapi.com)\n",
                "# =============================================================================\n",
                "\n",
                "import os\n",
                "from dotenv import load_dotenv\n",
                "\n",
                "load_dotenv()\n",
                "\n",
                "# Verify that API keys are loaded\n",
                "assert os.getenv('OPENAI_API_KEY'), \"OPENAI_API_KEY not found in environment\"\n",
                "assert os.getenv('TAVILY_API_KEY'), \"TAVILY_API_KEY not found in environment\"\n",
                "\n",
                "# Get Weather API key\n",
                "WEATHER_API_KEY = os.getenv('WEATHER_API_KEY')\n",
                "\n",
                "print(\"‚úÖ Environment variables loaded successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section2-header",
            "metadata": {},
            "source": [
                "---\n",
                "## üõ†Ô∏è Section 2: Create Travel Tools\n",
                "\n",
                "We need two tools for our travel assistant:\n",
                "\n",
                "1. **`search_web_extract_info`**: Searches the web for local attractions using Tavily API\n",
                "2. **`get_weather`**: Fetches current weather using WeatherAPI.com\n",
                "\n",
                "### Key Concepts:\n",
                "- The `@tool` decorator converts Python functions into LangChain tools\n",
                "- **Docstrings are critical** - the LLM uses them to decide when to call each tool\n",
                "- Tools should handle errors gracefully and return meaningful messages"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create-tools",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TRAVEL ASSISTANT TOOLS\n",
                "# =============================================================================\n",
                "# Tool 1: Web Search - Finds local attractions using Tavily API\n",
                "# Tool 2: Weather - Gets current weather using WeatherAPI.com\n",
                "# =============================================================================\n",
                "\n",
                "from langchain_core.tools import tool\n",
                "from markitdown import MarkItDown\n",
                "from langchain_community.tools.tavily_search import TavilySearchResults\n",
                "from tqdm import tqdm\n",
                "from concurrent.futures import ThreadPoolExecutor, TimeoutError\n",
                "import requests\n",
                "from warnings import filterwarnings\n",
                "\n",
                "filterwarnings('ignore')\n",
                "\n",
                "# -----------------------------------------------------------------------------\n",
                "# TOOL 1: Web Search for Local Attractions\n",
                "# -----------------------------------------------------------------------------\n",
                "# Initialize Tavily search with basic settings (faster, good for location queries)\n",
                "tavily_tool = TavilySearchResults(\n",
                "    max_results=5,           # Return top 5 results\n",
                "    search_depth='basic',    # Basic search is faster and sufficient for attractions\n",
                "    include_answer=False,    # We'll process results ourselves\n",
                "    include_raw_content=True # Include page content\n",
                ")\n",
                "\n",
                "# Configure HTTP session with browser-like headers to avoid bot detection\n",
                "session = requests.Session()\n",
                "session.headers.update({\n",
                "    \"User-Agent\": \"Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36 (KHTML, like Gecko) Chrome/112.0.0.0 Safari/537.36\",\n",
                "    \"Accept-Language\": \"en-US,en;q=0.9\",\n",
                "    \"Accept-Encoding\": \"gzip, deflate, br\"\n",
                "})\n",
                "\n",
                "# MarkItDown converts web pages to readable text\n",
                "md = MarkItDown(requests_session=session)\n",
                "\n",
                "@tool\n",
                "def search_web_extract_info(query: str) -> list:\n",
                "    \"\"\"\n",
                "    Search the web for a query and extract useful information from the search links.\n",
                "    \n",
                "    Use this tool to find:\n",
                "    - Local attractions and tourist spots\n",
                "    - Things to do in a destination\n",
                "    - Travel guides and recommendations\n",
                "    \n",
                "    Args:\n",
                "        query (str): The search query (e.g., \"local attractions in Kolkata\")\n",
                "        \n",
                "    Returns:\n",
                "        list: Extracted content from relevant web pages\n",
                "    \"\"\"\n",
                "    print('üîç Calling web search tool...')\n",
                "    results = tavily_tool.invoke(query)\n",
                "    docs = []\n",
                "\n",
                "    def extract_content(url):\n",
                "        \"\"\"Helper function to extract content from a URL.\"\"\"\n",
                "        extracted_info = md.convert(url)\n",
                "        text_title = extracted_info.title.strip()\n",
                "        text_content = extracted_info.text_content.strip()\n",
                "        return text_title + '\\n' + text_content\n",
                "    \n",
                "    # Process URLs in parallel for faster extraction\n",
                "    with ThreadPoolExecutor() as executor:\n",
                "        for result in tqdm(results, desc=\"Extracting content\"):\n",
                "            try:\n",
                "                future = executor.submit(extract_content, result['url'])\n",
                "                content = future.result(timeout=15)  # 15-second timeout\n",
                "                docs.append(content)\n",
                "            except TimeoutError:\n",
                "                print(f\"‚è∞ Extraction timed out for url: {result['url']}\")\n",
                "            except Exception as e:\n",
                "                print(f\"‚ùå Error extracting from url: {result['url']} - {e}\")\n",
                "\n",
                "    return docs\n",
                "\n",
                "\n",
                "# -----------------------------------------------------------------------------\n",
                "# TOOL 2: Weather Information\n",
                "# -----------------------------------------------------------------------------\n",
                "# Uses WeatherAPI.com for current weather data\n",
                "\n",
                "@tool\n",
                "def get_weather(query: str) -> dict:\n",
                "    \"\"\"\n",
                "    Get the current weather for a specified location.\n",
                "    \n",
                "    Use this tool whenever the user asks about:\n",
                "    - Current weather conditions\n",
                "    - Temperature at a destination\n",
                "    - Weather for travel planning\n",
                "    \n",
                "    Args:\n",
                "        query (str): The location/city name (e.g., \"Kolkata\", \"Mumbai\")\n",
                "        \n",
                "    Returns:\n",
                "        dict: Weather data including temperature, condition, humidity, etc.\n",
                "              Returns \"Weather Data Not Found\" if location is invalid\n",
                "    \"\"\"\n",
                "    print('üå§Ô∏è Calling weather tool...')\n",
                "    \n",
                "    # WeatherAPI.com endpoint\n",
                "    base_url = \"http://api.weatherapi.com/v1/current.json\"\n",
                "    complete_url = f\"{base_url}?key={WEATHER_API_KEY}&q={query}\"\n",
                "\n",
                "    response = requests.get(complete_url)\n",
                "    data = response.json()\n",
                "    \n",
                "    # Check if location was found\n",
                "    if data.get(\"location\"):\n",
                "        return data\n",
                "    else:\n",
                "        return \"Weather Data Not Found\"\n",
                "\n",
                "\n",
                "print(\"‚úÖ Travel tools created successfully!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "test-tools-header",
            "metadata": {},
            "source": [
                "### Test the Weather Tool\n",
                "Let's verify the weather tool works before building the agent."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "test-weather",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TEST: Weather Tool\n",
                "# =============================================================================\n",
                "# Verify the tool works correctly before using it in the agent\n",
                "\n",
                "result = get_weather.invoke(\"Kolkata\")\n",
                "print(f\"Weather result type: {type(result)}\")\n",
                "print(f\"Result: {result}\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section3-header",
            "metadata": {},
            "source": [
                "---\n",
                "## ü§ñ Section 3: Build the Travel Assistant Agent\n",
                "\n",
                "Now we'll create the agent with:\n",
                "1. **System Prompt**: Defines the agent's behavior as a travel assistant\n",
                "2. **Tool Binding**: Connect our search and weather tools to the LLM\n",
                "3. **AgentExecutor**: Runtime that executes agent decisions"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "test-tool-calling",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TEST: LLM Tool Calling Ability\n",
                "# =============================================================================\n",
                "# Before building the full agent, let's verify the LLM can correctly\n",
                "# identify which tools to use for a travel query.\n",
                "# =============================================================================\n",
                "\n",
                "from langchain_openai import ChatOpenAI\n",
                "\n",
                "chatgpt = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
                "tools = [search_web_extract_info, get_weather]\n",
                "\n",
                "# Bind tools to the LLM\n",
                "chatgpt_with_tools = chatgpt.bind_tools(tools)\n",
                "\n",
                "# Test: This query should trigger BOTH tools (attractions + weather)\n",
                "prompt = \"Show me Local Attractions in Bangalore and The Weather in Bangalore\"\n",
                "response = chatgpt_with_tools.invoke(prompt)\n",
                "\n",
                "print(\"Tool calls identified by the LLM:\")\n",
                "for tc in response.tool_calls:\n",
                "    print(f\"  ‚Ä¢ {tc['name']}: {tc['args']}\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create-prompt",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# CREATE THE TRAVEL ASSISTANT SYSTEM PROMPT\n",
                "# =============================================================================\n",
                "# The system prompt defines:\n",
                "# 1. The agent's role as a travel assistant\n",
                "# 2. The ReAct workflow (Thought ‚Üí Action ‚Üí Observation ‚Üí Answer)\n",
                "# 3. Special instruction to provide both attractions AND weather\n",
                "# 4. Available tools and when to use them\n",
                "# =============================================================================\n",
                "\n",
                "from langchain_core.prompts import ChatPromptTemplate, MessagesPlaceholder\n",
                "\n",
                "SYS_PROMPT = \"\"\"Act as a helpful travel assistant.\n",
                "                You run in a loop of Thought, Action, PAUSE, Observation.\n",
                "                At the end of the loop, you output an Answer.\n",
                "                Use Thought to describe your thoughts about the question you have been asked.\n",
                "                Use Action to run one of the actions available to you - then return PAUSE.\n",
                "                Observation will be the result of running those actions.\n",
                "                Repeat till you get to the answer for the given user query.\n",
                "                \n",
                "                IMPORTANT: When a user asks about a destination or location:\n",
                "                1. Search for local attractions and tourist spots\n",
                "                2. Get the current weather for that location\n",
                "                3. Provide the attractions as bullet points with the weather information\n",
                "                \n",
                "                Use the following workflow format:\n",
                "                  Question: the input task you must solve\n",
                "                  Thought: you should always think about what to do\n",
                "                  Action: the action to take which can be any of the following:\n",
                "                            - break it into smaller steps if needed\n",
                "                            - see if you can answer the given task with your trained knowledge\n",
                "                            - call the most relevant tools at your disposal mentioned below in case you need more information\n",
                "                  Action Input: the input to the action\n",
                "                  Observation: the result of the action\n",
                "                  ... (this Thought/Action/Action Input/Observation can repeat N times)\n",
                "                  Thought: I now know the final answer\n",
                "                  Final Answer: the final answer to the original input question\n",
                "\n",
                "                \n",
                "                Tools at your disposal to perform tasks as needed:\n",
                "                  - get_weather: whenever user asks get the weather of a place.\n",
                "                  - search_web_extract_info: whenever user asks for specific information or if you don't know the answer.\n",
                "             \"\"\"\n",
                "\n",
                "prompt_template = ChatPromptTemplate.from_messages(\n",
                "    [\n",
                "        (\"system\", SYS_PROMPT),\n",
                "        MessagesPlaceholder(variable_name=\"history\", optional=True),\n",
                "        (\"human\", \"{query}\"),\n",
                "        MessagesPlaceholder(variable_name=\"agent_scratchpad\"),\n",
                "    ]\n",
                ")\n",
                "\n",
                "print(\"‚úÖ System prompt created!\")"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "create-agent",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# CREATE THE TRAVEL ASSISTANT AGENT\n",
                "# =============================================================================\n",
                "# Components:\n",
                "# 1. LLM (gpt-4o-mini) - faster and more cost-effective for this use case\n",
                "# 2. Tools - search_web_extract_info and get_weather\n",
                "# 3. Prompt Template - our travel-focused system prompt\n",
                "# 4. AgentExecutor - runs the agent and handles tool execution\n",
                "# =============================================================================\n",
                "\n",
                "from langchain.agents import create_tool_calling_agent, AgentExecutor\n",
                "\n",
                "# Using gpt-4o-mini for faster, more cost-effective responses\n",
                "chatgpt = ChatOpenAI(model=\"gpt-4o-mini\", temperature=0)\n",
                "tools = [search_web_extract_info, get_weather]\n",
                "\n",
                "# Create the agent (decision-maker)\n",
                "agent = create_tool_calling_agent(chatgpt, tools, prompt_template)\n",
                "\n",
                "# Create the executor (runs the agent and tools)\n",
                "agent_executor = AgentExecutor(\n",
                "    agent=agent,\n",
                "    tools=tools,\n",
                "    early_stopping_method='force',  # Force stop at max iterations\n",
                "    max_iterations=10               # Prevent infinite loops\n",
                ")\n",
                "\n",
                "print(\"‚úÖ Travel assistant agent created!\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "section4-header",
            "metadata": {},
            "source": [
                "---\n",
                "## üß™ Section 4: Test the Travel Assistant\n",
                "\n",
                "Let's test our travel assistant with a destination query."
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "helper-function",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# HELPER FUNCTION: Extract Final Answer\n",
                "# =============================================================================\n",
                "# The agent's response includes the full reasoning chain. This function\n",
                "# extracts just the \"Final Answer\" portion for cleaner display.\n",
                "# =============================================================================\n",
                "\n",
                "import re\n",
                "\n",
                "def extract_final_answer(agent_response):\n",
                "    \"\"\"\n",
                "    Extract the Final Answer portion from the agent response.\n",
                "    \n",
                "    Args:\n",
                "        agent_response (dict): The response from agent_executor.invoke()\n",
                "    \n",
                "    Returns:\n",
                "        str: The final answer content only\n",
                "    \"\"\"\n",
                "    output = agent_response['output']\n",
                "    \n",
                "    match = re.search(r'Final Answer:\\s*(.*)', output, re.DOTALL)\n",
                "    if match:\n",
                "        return match.group(1).strip()\n",
                "    else:\n",
                "        return output  # Return full output if no \"Final Answer\" marker found"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "test-agent",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# TEST: Travel Query - Kolkata\n",
                "# =============================================================================\n",
                "# The agent should:\n",
                "# 1. Search for local attractions in Kolkata\n",
                "# 2. Get the current weather in Kolkata\n",
                "# 3. Combine both into a helpful travel response\n",
                "# =============================================================================\n",
                "\n",
                "from IPython.display import display, Markdown\n",
                "\n",
                "query = \"Kolkata\"\n",
                "print(f\"üó∫Ô∏è Query: {query}\")\n",
                "print(\"=\"*60)\n",
                "\n",
                "# Invoke the agent\n",
                "resp = agent_executor.invoke({\"query\": query})\n",
                "\n",
                "# Display the full agent response (includes reasoning chain)\n",
                "print(\"\\nüìã Full Agent Response:\")\n",
                "display(Markdown(resp[\"output\"]))"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "display-final",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# DISPLAY: Final Answer Only\n",
                "# =============================================================================\n",
                "# For a cleaner presentation, show only the final answer\n",
                "\n",
                "final_answer = extract_final_answer(resp)\n",
                "\n",
                "print(\"\\nüéØ Final Answer:\")\n",
                "display(Markdown(final_answer))"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "summary-header",
            "metadata": {},
            "source": [
                "---\n",
                "## üìù Summary and Assignment Completion\n",
                "\n",
                "### What You Built\n",
                "An **Intelligent Travel Assistant** that:\n",
                "- ‚úÖ Uses web search to find local attractions\n",
                "- ‚úÖ Fetches real-time weather data\n",
                "- ‚úÖ Combines both into helpful travel information\n",
                "- ‚úÖ Follows the ReAct reasoning pattern\n",
                "\n",
                "### Key Concepts Practiced\n",
                "| Concept | Implementation |\n",
                "|---------|---------------|\n",
                "| Custom Tools | `@tool` decorator with Tavily and WeatherAPI |\n",
                "| System Prompt | ReAct pattern + travel-specific instructions |\n",
                "| Tool Calling Agent | `create_tool_calling_agent` with GPT-4o-mini |\n",
                "| AgentExecutor | Runtime with early stopping and max iterations |\n",
                "\n",
                "### Bonus Exercises\n",
                "1. **Add Memory**: Use `SQLChatMessageHistory` to remember user preferences\n",
                "2. **More Tools**: Add tools for flight prices, hotel recommendations, or restaurant search\n",
                "3. **Multi-City**: Extend the agent to compare multiple destinations\n",
                "4. **Streaming**: Use `stream` instead of `invoke` for real-time responses"
            ]
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "id": "bonus-exercise",
            "metadata": {},
            "outputs": [],
            "source": [
                "# =============================================================================\n",
                "# BONUS: Try Other Destinations!\n",
                "# =============================================================================\n",
                "# Uncomment and modify to test with different cities\n",
                "\n",
                "# destinations = [\"Mumbai\", \"Delhi\", \"Jaipur\", \"Goa\", \"Varanasi\"]\n",
                "# \n",
                "# for destination in destinations:\n",
                "#     print(f\"\\nüó∫Ô∏è Query: {destination}\")\n",
                "#     print(\"=\"*60)\n",
                "#     resp = agent_executor.invoke({\"query\": destination})\n",
                "#     final_answer = extract_final_answer(resp)\n",
                "#     display(Markdown(final_answer))\n",
                "#     print(\"\\n\")"
            ]
        },
        {
            "cell_type": "markdown",
            "id": "c8e1c146",
            "metadata": {},
            "source": [
                "# LLM Reasoning Implementation Analysis\n",
                "\n",
                "Based on the provided code, here's a detailed explanation of how the LLM is used for reasoning:\n",
                "\n",
                "## Overview\n",
                "\n",
                "This implementation creates an **agent-based reasoning system** using LangChain that follows a **ReAct (Reasoning + Acting) pattern**. The LLM (GPT-4o-mini) acts as a reasoning engine that can think through problems step-by-step and take actions using available tools.\n",
                "\n",
                "## Core Reasoning Architecture\n",
                "\n",
                "### 1. **ReAct Framework Implementation**\n",
                "\n",
                "The system implements a classic ReAct loop where the LLM:\n",
                "\n",
                "- **Thinks** about the problem\n",
                "- **Acts** by calling appropriate tools\n",
                "- **Observes** the results\n",
                "- **Repeats** until reaching a conclusion\n",
                "\n",
                "### 2. **Structured Reasoning Prompt**\n",
                "\n",
                "The reasoning is guided by a detailed system prompt that enforces a specific workflow:\n",
                "\n",
                "```\n",
                "Question ‚Üí Thought ‚Üí Action ‚Üí Action Input ‚Üí Observation ‚Üí [Loop] ‚Üí Final Answer\n",
                "```\n",
                "\n",
                "### 3. **How the Reasoning Step Works**\n",
                "\n",
                "#### **Step 1: Problem Analysis**\n",
                "\n",
                "- The LLM receives a user query and analyzes what information is needed\n",
                "- It determines whether it can answer with existing knowledge or needs external data\n",
                "\n",
                "#### **Step 2: Strategic Planning**\n",
                "\n",
                "- The LLM breaks down complex queries into smaller, manageable steps\n",
                "- For example, if asked about \"Local Attractions in Bangalore and Weather\", it identifies two separate tasks\n",
                "\n",
                "#### **Step 3: Tool Selection**\n",
                "\n",
                "The LLM has access to two specialized tools:\n",
                "\n",
                "- **`search_web_extract_info`**: For gathering information from web sources\n",
                "- **`get_weather`**: For retrieving current weather data\n",
                "\n",
                "#### **Step 4: Iterative Execution**\n",
                "\n",
                "- The LLM calls appropriate tools based on its reasoning\n",
                "- It processes the results and determines if additional actions are needed\n",
                "- Maximum of 10 iterations prevents infinite loops\n",
                "\n",
                "#### **Step 5: Synthesis and Response**\n",
                "\n",
                "- After gathering all necessary information, the LLM synthesizes the data\n",
                "- It provides a comprehensive \"Final Answer\" that addresses the original query\n",
                "\n",
                "## Key Reasoning Features\n",
                "\n",
                "### **Multi-Step Reasoning**\n",
                "\n",
                "- The agent can handle complex queries requiring multiple information sources\n",
                "- It maintains context across multiple tool calls and reasoning steps\n",
                "\n",
                "### **Adaptive Strategy**\n",
                "\n",
                "- The LLM can decide between using its trained knowledge vs. calling external tools\n",
                "- It adapts its approach based on the type of information needed\n",
                "\n",
                "### **Error Handling and Recovery**\n",
                "\n",
                "- The system includes timeout mechanisms and error handling for tool calls\n",
                "- The reasoning process can continue even if some tool calls fail\n",
                "\n",
                "### **Structured Output**\n",
                "\n",
                "- The reasoning process is transparent, showing each thought and action\n",
                "- The final answer is clearly separated from the reasoning process\n",
                "\n",
                "## Example Reasoning Flow\n",
                "\n",
                "For a query like \"Kolkata\":\n",
                "\n",
                "1. **Thought**: \"The user mentioned Kolkata. I should provide local attractions and current weather\"\n",
                "2. **Action**: Call `search_web_extract_info` for Kolkata attractions\n",
                "3. **Observation**: Process web search results\n",
                "4. **Action**: Call `get_weather` for Kolkata weather\n",
                "5. **Observation**: Process weather data\n",
                "6. **Final Answer**: Synthesize both pieces of information into a comprehensive response\n",
                "\n",
                "## Technical Implementation Details\n",
                "\n",
                "- **LLM Model**: GPT-4o-mini with temperature=0 for consistent reasoning\n",
                "- **Framework**: LangChain's AgentExecutor with tool-calling capabilities\n",
                "- **Concurrency**: Parallel processing of web content extraction using ThreadPoolExecutor\n",
                "- **Safety**: Early stopping mechanism and iteration limits prevent runaway processes\n",
                "\n",
                "This implementation demonstrates sophisticated **multi-modal reasoning** where the LLM acts as an orchestrator, combining its inherent knowledge with real-time data retrieval capabilities to provide comprehensive, well-reasoned responses.\n"
            ]
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "venv",
            "language": "python",
            "name": "python3"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.11.6"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 5
}
